\documentclass[Dissertation.tex]{subfiles} 
\begin{document}


\chapter{Computation}
\label{chp:Computation}


\section{Short-Range -- Short-Range Integrations}
\label{sec:ShortShortIntegration}
The short-range -- short-range integrals make up the bulk of the $A$ matrix (equation \ref{eq:GenKohnMatrixAXB}). The positronium hydride bound state problem in chapter \ref{chp:PsHBound} consists of only these types of matrix elements (see equation \ref{eq:BoundWavefn}). The most general form of these short-range integrals is

\beq
I \equiv I(k_i, l_i, m_i, n_i, p_i, q_i; \alpha, \beta, \gamma) = \int e^{-(\alpha r_1 + \beta r_2 + \gamma r_3)} r_1^{k_i} r_2^{l_i} r_{12}^{m_i} r_3^{n_i} r_{13}^{p_i} r_{23}^{q_i} d\textbf{r}_1 d\textbf{r}_2 d\textbf{r}_3.
\eeq
This class of integrals, the so-called Hylleraas three-electron or four-body integrals, has been studied extensively. See references \cite{Drake1995}, \cite{Frolov2003}, \cite{Pelzl1998} and \cite{Pachucki2004} for just some of the papers detailing strategies on how to compute these integrals. The first three papers here use the same infinite summation to numerically solve this integral but use different techniques to accelerate the convergence, as the summation converges slowly for some arguments. The last paper by Pachucki et al.\ uses a very different approach with recursion relations, described in section \ref{sec:RecursionRelations}.

The general form of the infinite summation for $I$ is
\beq
I = \sum_{q=0}^\infty T(q),
\eeq
where $T(q)$ is given by Drake and others \cite{Drake1995,Frolov2003}. In the case where any of $m_i$, $p_i$ or $q_i$ are even, the summation collapses to a finite summation, making the calculations exact to numerical accuracy. Early attempts at using a Hylleraas-type basis restricted one of the $r_{ij}$ powers to be even for this reason, but the full calculation for the energy converged slowly \cite{?}.

\todoi{Not true ($\geq 2?$. Add more references other than \cite{Pelzl2002}.}
In our calculations, $k_i$, $l_i$, $m_i$, $n_i$, $p_i$ and $q_i \geq -1$. Most of the techniques for solving these integrals only work when this condition is satisfied. More singular integrals can be solved in special cases \cite{Pelzl2002}, but these types of terms normally only appear when relativistic corrections are taken into account.

\subsection{Asymptotic Expansion}
\label{sec:AsymptoticExpansion}
The infinite summation for $I$ given in references \cite{Drake1995} and \cite{Frolov2003} can converge extremely slow when all $r_{ij}$ powers are odd, especially since we need as much accuracy in the matrix elements as possible. As an example in Drake and Yan's paper \cite{Drake1995}, direct calculation of this summation for $I(0,0,0,-1,-1,-1; 1,1,1)$ only reaches an accuracy of $1.5 x 10^{-13}$ after 6860 terms. With their asymptotic expansion method, the integral has converged to approximately $2.2 x 10^{-16}$ after only 21 terms.

The summation converges monotonically and asymptotically. Drake and Yan use this knowledge to speed up the convergence of the integration. Details of this method can be found in their paper \cite{Drake1995}.

This asymptotic expansion method was used in all calculations of the S-wave and performed very well. The accuracy is good, and the integrations complete in a reasonable amount of time, on the order of hours normally. After the S-wave calculations were completed, we learned of an analytic, instead of numerical, solution to these three-electron integrals, derived by Pachucki et al.\ \cite{Pachucki2004}.

\subsection{Recursion Relations}
\label{sec:RecursionRelations}
Pachucki et al.\ were not the first to derive an analytic solution to the three-electron integrals \cite{Pachucki2004}, but the first by Fromm and Hill is not very practical to use, considering its very complicated form \cite{Fromm1987}. Each set of $r_i$ and $r_{ij}$ powers requires a new rederivation from the Fromm and Hill result. The recursion relations from Pachucki are complicated but also general.

Since the recursion relations are an analytic solution, we can get any desired precision that we choose. The calculations previously with the asymptotic expansion used double precision, but we chose quadruple precision for the recursion relations. Part of this choice is that just like many other types of recursion relations, these relations may not be stable for higher $\omega$ values without the increased precision. We have tested through $\omega = 8$, and this method produced stable results. In some of their work on Li and Be$^+$, their group uses sextuple precision, as quadruple precision becomes insufficient near $\omega = 10$ \cite{Puchalski}, which is much higher than we can use in the scattering calculations.

\subsection{W Functions}
\label{sec:WFunctions}

\begin{table}[H]
\centering
\begin{tabular}{c c c c}
\toprule
$\omega$ & Used Terms & Total Terms & Percentage Used \\
\midrule
1 & 	115   &  20,000 & 	0.575\% \\
2 & 	921   &  27,040 & 	3.41\% \\
3 & 	1,939 &  34,992 & 	5.54\% \\
4 & 	3,140 &  43,904 & 	7.15\% \\
5 & 	4,573 &  53,824 &	8.49\% \\
6 & 	6,246 &  64,800 &	9.64\% \\
7 & 	8,147 &  76,880 &	10.6\% \\
\bottomrule
\end{tabular}
\caption{S-Wave W Function Terms Used}
\label{tab:WFuncUnusedS}
\end{table}



\begin{table}[H]
\centering
\begin{tabular}{c c c c}
\toprule
$\omega$ & Used Terms & Total Terms & Percentage Used \\
\midrule
0 & 150		&	196,290 &	0.0764\% \\
1 & 1,670	&	259,932 &	0.642\% \\
2 & 14,076	&	332,262 &	4.24\% \\
3 & 23,384	&	413,520 &	5.65\% \\
4 & 36,418	&	503,946 &	7.23\% \\
5 & 51,420 &	603,780 &	8.52\% \\
6 & 68,438	&	713,262 &	9.60\% \\
7 & 87,520 &	832,632 &  10.5\% \\
\bottomrule
\end{tabular}
\caption{D-Wave W Function Terms Used}
\label{tab:WFuncUnusedD}
\end{table}


\section{Perimetric Coordinates}
\label{sec:PerimetricCoords}

Perimetric coordinates are used for some integrations.  If perimetric coordinates are used for $r_1$, $r_2$ and $r_{12}$, then these are defined by \cite{Armour1991}

\begin{align}
\label{eq:PerimetricCoords1}
\nonumber x &= r_1 + r_2 - r_{12} \\
\nonumber y &= r_2 + r_{12} - r_1 \\
z &= r_{12} + r_1 - r_2.
\end{align}

These can alternately be written as
\begin{align}
\label{eq:PerimetricCoords2}
\nonumber r_1 &= \frac{x+z}{2} \\
\nonumber r_2 &= \frac{x+y}{2} \\
\nonumber r_{12} &= \frac{y+z}{2}.
\end{align}

From equation \ref{}, the volume element after integration over the external angles is


\beq
\label{eq:dtau}
d\tau = 8\pi^2 dr_1 r_2 dr_2 r_3 dr_3 r_{12} dr_{12} r_{13} dr_{13} d\phi_{23}.
\eeq

We need to perform a change of variables to use perimetric coordinates for $r_1$, $r_2$ and $r_{12}$.  The Jacobian is
\beq
\label{eq:PerimetricJacobian}
J(x,y,z) = 
\left| {\begin{array}{ccc}
 \frac{\partial r_1}{\partial x} & \frac{\partial r_1}{\partial y} & \frac{\partial r_1}{\partial z}  \\
 \frac{\partial r_2}{\partial x} & \frac{\partial r_2}{\partial y} & \frac{\partial r_2}{\partial z}  \\
 \frac{\partial r_{12}}{\partial x} & \frac{\partial r_{12}}{\partial y} & \frac{\partial r_{12}}{\partial z}  \\
 \end{array} } \right|
=
\left| {\begin{array}{ccc}
 \frac{1}{2} & 0 & \frac{1}{2} \\
 \frac{1}{2} & \frac{1}{2} & 0 \\
 0 & \frac{1}{2} & \frac{1}{2}
 \end{array} } \right|
=
\frac{1}{4}.
\eeq

\noindent This gives a transformed volume element of
\beq
\label{eq:PerimetricVolEl}
d\tau = 2\pi^2 r_2 r_3 r_{12} r_{13} dx\, dy\, dz\, dr_3\, dr_{13}\, d\phi_{23}.
\eeq

\noindent The limits for each of the perimetric coordinates are 0 to $\infty$.


\section{Gaussian Quadratures}
\label{sec:GaussQuad}
Gaussian quadratures are used to integrate many classes of integrals.  In their most general form, these quadratures are given by
\beq
\label{eq:GeneralQuadratures}
\int_a^b W(x) f(x) dx \approx \sum_{i=1}^n w_i f(x_i).
\eeq

\noindent Gaussian quadratures are particularly attractive, since they give exact results for polynomials up to degree $2n-1$.  The weight function $W(x)$ can be chosen for certain classes of integrals.  Three main types of weight functions are used in this work.


\subsection{Gauss-Legendre Quadrature}
\label{sec:GaussLegendre}
If the weight function is chosen as $W(x)=1$, and the integration interval is $(-1,1)$, this is known as Gauss-Legendre quadrature (or sometimes known simply as Gaussian quadrature).  The orthogonal polynomials used are the Legendre polynomials, $P_n(x)$.  Equation \ref{eq:GeneralQuadratures} becomes
\beq
\label{eq:GaussLeg}
\int_{-1}^1 f(x) dx \approx \sum_{i=1}^n w_i f(x_i),
\eeq
where the $x_i$ abscissas are the $i^{th}$ zeros of $L_n(x)$, and the weights are given by
\beq
\label{eq:GaussLegWeights}
w_i = \frac{2}{(1-x_i^2)[P^\prime_n(x_i)]^2}.
\eeq

The limits of integration must be from $-1$ to $1$, but this is generalized by using the transformation \cite{Abramowitz1965}
\begin{align}
\label{eq:GaussLegGen}
\int_a^b f(x) dx &= \frac{b-a}{2} \int_{-1}^1 f \left(\frac{b-a}{2} x + \frac{a+b}{2}\right) dx \\
&\approx \frac{b-a}{2} \sum_{i=1}^n w_i f \left(\frac{b-a}{2} x_i + \frac{a+b}{2}\right).
\end{align}


\subsection{Gauss-Laguerre Quadrature}
\label{sec:GaussLag}
The Gauss-Legendre quadrature cannot be used on semi-infinite intervals, so we use the Gauss-Laguerre quadrature in these cases.  The orthogonal polynomials in this case are the Laguerre polynomials, $L_n(x)$, and the weight function is $W(x) = e^{-x}$.  Equation \ref{eq:GeneralQuadratures} becomes
\beq
\label{eq:GaussLag}
\int_0^\infty e^{-x} f(x) dx \approx \sum_{i=1}^n w_i f(x_i),
\eeq
where the $x_i$ abscissas are the $i^{th}$ zeros of $L_n(x)$, and the weights are given by
\beq
\label{eq:GaussLagWeights}
w_i = \frac{x_i}{(n+1)^2 [L_{n+1}(x_i)]^2}.
\eeq

When the integration is over the interval $(a,\infty)$, equation \ref{eq:GaussLag} is easily transformed by
\beq
\label{eq:GaussLagGen1}
\int_a^\infty e^{-x} f(x) dx = \int_0^\infty e^{-(x+a)} f(x+a) dx = e^{-a} \int_0^\infty e^{-x} f(x+a) dx \approx e^{-a} \sum_{i=1}^n w_i f(x_i+a).
\eeq

\noindent A more general form of this is obtained by using a coefficient in the exponential, i.e.
\beq
\label{eq:GaussLagGen2}
\int_a^\infty e^{-m x} f(x) dx = \frac{1}{m} \int_a^\infty e^{-y} f\left(\frac{y}{m}\right) dy,
\eeq
where we have defined $y = m x$.  This allows for equation \ref{eq:GaussLagGen1} to be generalized to
\begin{align}
\label{eq:GaussLagGen}
\nonumber \int_a^\infty e^{-m x} f(x) dx &= \frac{1}{m} \int_{ma}^\infty e^{-y} f\left(\frac{y}{m}\right) dy = \frac{1}{m} \int_0^\infty e^{-(y+ma)} f\left(\frac{y}{m}+a\right) dy \\
& = \frac{e^{-ma}}{m} \int_0^\infty e^{-y} f\left(\frac{y}{m}+a\right) dy \approx \frac{e^{-ma}}{m} \sum_{i=1}^n w_i f\left(\frac{y_i}{m}+a\right).
\end{align}
The $y_i$ abscissas and $w_i$ weights are the same as the less general case in equations \ref{eq:GaussLag} and \ref{eq:GaussLagWeights}.  This general form of Gauss-Laguerre quadrature is what we use for our semi-infinite integrations.


\subsection{Chebyshev--Gauss Quadrature}
\label{sec:ChebyshevGauss1}
If the weight function is chosen as $W(x)=\frac{1}{\sqrt{1-x^2}}$, and the integration interval is $(-1,1)$, this is known as Chebyshev--Gauss quadrature.  The orthogonal polynomials used are the Chebyshev polynomials of the first kind, $T_n(x)$.  Equation \ref{eq:GeneralQuadratures} becomes
\beq
\label{eq:GaussCheb}
\int_{-1}^1 \frac{f(x)}{\sqrt{1-x^2}} dx \approx \sum_{i=1}^n w_i f(x_i),
\eeq
where
\beq
\label{eq:GaussChebAbsWeights}
x_i = \cos\left(\frac{2i-1}{n}\pi\right) \text{ and } w_i = \frac{\pi}{n}.
\eeq

This quadrature is used for the internal angular integrations.  A discussion of how to use this for these integrations is found in appendix \ref{sec:ChebyshevGauss}.

\section{Long-Range -- Long-Range}
\label{sec:LongLongInt}
The scattering program calculates only the short-range -- long-range (short-long) and long-range -- long-range (long-long) matrix elements.  The volume element in equation \ref{eq:dtau} has an internal angle of $\phi_{23}$ to integrate over.  When a term has a a negative power of $r_{23}$, a large number of integration points must be used for reasonable accuracy.  Instead, we split the integration such that one part is missing the the $r_{23}^{-1}$ term and the other contains only the $r_{23}^{-1}$ term.

The first integration excluding the $r_{23}^{-1}$ term has negative powers of $r_i$ and $r_{ij}$ cancelled by the corresponding terms in the volume element given by equation \ref{}.  For the integration over the $r_{23}^{-1}$ term, we use an alternative volume element, namely that given by equation \ref{}.  The $r_{23}^{-1}$ is then cancelled by the $r_{23}$ in this volume element.

\textbf{@TODO:} Add the section about the volume elements in an appendix.

\subsection{Integration without the \texorpdfstring{$r_{23}^{-1}$} {1/r23} term}
\label{sec:LongLongNoR23}
The simplest long-long matrix element to evaluate is $(\bar{S},L\bar{S})$.  From equation \ref{eq:SbarLSbar}, not including its $r_{23}^{-1}$ term, this is
\beq
(\bar{S},L\bar{S})_A = \pm \left(S^\prime,LS\right) = \pm \left(S^\prime, \left[ \frac{2}{r_1} - \frac{2}{r_2} - \frac{2}{r_{13}}\right] S\right).
\eeq

For this type of integration, we use perimetric coordinates as described in section \ref{sec:PerimetricCoords}.
\beq
\label{eq:SBarSBarInt}
(\bar{S},L\bar{S})_A = \pm 2\pi^2 \int_0^\infty \int_0^\infty \int_0^\infty \int_0^\infty \int_{|r_1 - r_3|}^{|r_1 + r_3|} \int_0^{2\pi}  S^\prime S \left[ \frac{2}{r_1} - \frac{2}{r_2} - \frac{2}{r_{13}}\right] r_2 r_3 r_{12} r_{13}\, d\phi_{23}\, dr_{13}\, dr_3\, dz\, dy\, dx
\eeq

The $\phi_{23}$ integration is done analytically.  Since $S$ and $S^\prime$ have no $r_{23}$ dependence and there is no $r_23$ term in the brackets, the integration over $\phi_{23}$ is simply $2\pi$.  The $r_{13}$ integration uses the Gauss-Laguerre quadrature from section \ref{sec:GaussLegendre}.  The $x$, $y$ and $z$ integrations use Gauss-Laguerre quadrature (section \ref{sec:GaussLag}), since they are semi-infinite.

\textbf{@TODO:} Describe the discontinuity and why it exists.

The $r_3$ integration could also be performed using just the Gauss-Laguerre quadrature.  However, the integrand for the $r_3$ integration has a discontinuity in its slope at $r_3=r_1$, creating a cusp, so the accuracy is improved greatly if we split the integration interval into two parts and employ different quadratures for each.  The integration is split to use Gauss-Legendre on the interval $(0,r_1)$ and Gauss-Laguerre on the interval $(r_1,\infty)$.

\subsection{Integration over the \texorpdfstring{$r_{23}^{-1}$} {1/r23} term}
%\subsection[Integration over the 1/r23 term]{Integration over the $r_{23}^{-1}$ term}
\label{sec:LongLongR23}
The other part of the $(\bar{S},L\bar{S})$ integral contains the $r_{23}^{-1}$ term.

\beq
(\bar{S},L\bar{S})_B = \pm \left(S^\prime, \left[ \frac{2}{r_{23}}\right] S\right)
\eeq

\textbf{@TODO:} Why exactly do we use perimetric coordinates?

\noindent The volume element for this integral is $d\tau^\prime$ from equation \ref{}.  The integration also does not need to be converted to perimetric coordinates, so its form is
\beq
(\bar{S},L\bar{S})_B = \pm 8\pi^2 \int_0^\infty \int_0^\infty \int_0^\infty \int_{|r_1 - r_3|}^{|r_1 + r_3|} \int_{|r_2 - r_3|}^{|r_2 + r_3|} \int_0^{2\pi}  S^\prime S \frac{2}{r_{23}} r_1 r_2 r_{13} r_{23}\, d\phi_{12}\, dr_{23}\, dr_{13}\, dr_2\, dr_3\, dr_1.
\eeq

The $r_{13}$ and $r_{23}$ integrals have finite limits, so here we use Gauss-Legendre quadrature.  Again, for the internal angular integration, this time over $\phi_{12}$, we use Chebyshev-Gauss quadrature.  The cusp in the $r_3$ integration is at $r_3 = r_1$, and the cusp in the $r_2$ integration is at $r_2 = r_3$.  Similar to before, we split up these integrations by using Gauss-Legendre before the cusp and Gauss-Laguerre after the cusp.

The $(\bar{C},L\bar{S})$ and $(\bar{C},L\bar{C})$ terms are integrated in the same manner as the $(\bar{S},L\bar{S})$ integral just described.


\section{Short-Range -- Long-Range}
\label{sec:ShortLongInt}
We will consider only the $(\bar{\phi}_i,L\bar{S})$ integrations here, as the $(\bar{\phi}_i,L\bar{C})$ integrals are evaluated in the same manner.  As in the case of long-range -- long-range integrations in section \ref{sec:LongLongInt}, we split up the integration into two parts -- one containing the $r_{23}^{-1}$ term and another containing the rest of the terms.  The short-range terms have the added benefit of the possibility of the polynomial $r_{23}^{\,q_i}$ being present, which cancels the $r_{23}^{-1}$ term or gives it an overall positive power.


From \ref{eq:PhiBarLSBar2b}, \ref{eq:LS2} and \ref{eq:LSP2}, 

\begin{align}
\label{eq:PhiLSBarInt}
\nonumber (\bar{\phi}_i, L\bar{S}) &= \frac{2}{\sqrt{2}} \left(\phi_i,L\bar{S}\right) \\
 &= \frac{2}{\sqrt{2}} \int \phi_i \left[ \left( \frac{2}{r_1} - \frac{2}{r_2} - \frac{2}{r_{13}} + \frac{2}{r_{23}} \right)S \pm \left( \frac{2}{r_1} - \frac{2}{r_3} - \frac{2}{r_{12}} + \frac{2}{r_{23}} \right) S^\prime \right]  d\tau.
\end{align}

\subsection{Case I: $q_i > 0$}
\label{sec:Swaveqigt0}
When $q_i > 0$ in $\phi_i$ (equation \ref{eq:PhiDef}), the power of $r_{23}$ is equal to or greater than 0.  Gaussian quadratures can safely integrate this type of term, so we integrate the full expression in equation \ref{eq:PhiLSBarInt}.
\begin{align}
\label{eq:PhiLSBarIntFull}
\nonumber (\bar{\phi}_i, L\bar{S}) =& \, \frac{2}{\sqrt{2}} \cdot 8\pi^2  \int_0^\infty \int_0^\infty \int_0^\infty \int_{|r_1 - r_2|}^{|r_1 + r_2|} \int_{|r_1 - r_3|}^{|r_1 + r_3|} \int_0^{2\pi} \phi_i \\
&\times \left[ \left( \frac{2}{r_1} - \frac{2}{r_2} - \frac{2}{r_{13}} + \frac{2}{r_{23}} \right)S \pm \left( \frac{2}{r_1} - \frac{2}{r_3} - \frac{2}{r_{12}} + \frac{2}{r_{23}} \right) S^\prime \right]  r_2 r_3 r_{12} r_{13}\, d\phi_{23}\, dr_{13}\, dr_{12}\, dr_3\, dr_2\, dr_1
\end{align}

Similar to the long-long integrations from section \ref{sec:LongLongInt}, the $r_1$ integration is performed using the Gauss-Laguerre quadrature.  The $r_2$ integral is broken into two parts at the cusp of $r_2 = r_1$, with the Gauss-Legendre quadrature before the cusp and the Gauss-Laguerre quadrature after the cusp.  In the $r_3$ coordinate, there is a cusp at $r_3 = r_2$, so the integration is also split up into Gauss-Legendre before the cusp and Gauss-Laguerre after the cusp.  The finite intervals for $r_{12}$ and $r_{13}$ ensure that we can use Gauss-Legendre quadratures for these coordinates.  The $\phi_{23}$ integration uses the Chebyshev-Gauss quadrature.

\subsection{Case II: $q_i = 0$}
When $q_i = 0$, the overall power of the $r_{23}^{-1}$ term is $-1$, so we cannot use the Gaussian quadratures in the form of \ref{eq:PhiLSBarIntFull}.  Similar to the long-long integrations, the $r_{23}^{-1}$ term is integrated separately, using the same type of integrations as equation \ref{eq:PhiLSBarIntFull}.  Refer to the previous section for the description of the quadratures used.
\begin{align}
\label{eq:PhiLSBarIntNoR23}
\nonumber (\bar{\phi}_i, L\bar{S}) =& \,\frac{2}{\sqrt{2}} \int \phi_i \left[ \left( \frac{2}{r_1} - \frac{2}{r_2} - \frac{2}{r_{13}} \right)S \pm \left( \frac{2}{r_1} - \frac{2}{r_3} - \frac{2}{r_{12}} \right) S^\prime \right]  d\tau \\
=&\, \frac{2}{\sqrt{2}} \cdot 8\pi^2  \int_0^\infty \int_0^\infty \int_0^\infty \int_{|r_1 - r_2|}^{|r_1 + r_2|} \int_{|r_1 - r_3|}^{|r_1 + r_3|} \int_0^{2\pi} \phi_i \\
&\times \left[ \left( \frac{2}{r_1} - \frac{2}{r_2} - \frac{2}{r_{13}} \right)S \pm \left( \frac{2}{r_1} - \frac{2}{r_3} - \frac{2}{r_{12}} \right) S^\prime \right]  r_2 r_3 r_{12} r_{13}\, d\phi_{23}\, dr_{13}\, dr_{12}\, dr_3\, dr_2\, dr_1
\end{align}

The integration over the $r_{23}^{-1}$ term is done the same way as the second integration of the long-long matrix elements in section \ref{sec:LongLongInt}.  The $r_{23}$ in the $d\tau^\prime$ volume element cancels the $r_{23}^{-1}$ term.  Refer to section \ref{sec:LongLongR23} for a description of the quadratures used here.
\begin{align}
\label{eq:PhiLSBarIntR23}
\nonumber (\bar{\phi}_i, L\bar{S}) =& \,\frac{2}{\sqrt{2}} \int \phi_i \left[ \frac{2}{r_{23}}\left(S \pm S^\prime\right) \right] d\tau^\prime \\
=&\, \frac{2}{\sqrt{2}} \cdot 8\pi^2  \int_0^\infty \int_0^\infty \int_0^\infty \int_{|r_1 - r_3|}^{|r_1 + r_3|} \int_{|r_2 - r_3|}^{|r_2 + r_3|} \int_0^{2\pi} \phi_i \\
&\times \left[ \frac{2}{r_{23}}\left(S \pm S^\prime\right) \right]  r_1 r_2 r_{13} r_{23}\, d\phi_{12}\, dr_{23}\, dr_{13}\, dr_2\, dr_3\, dr_1
\end{align}

\section{Notation}
\label{sec:CompNotation}
The bound state problem is a generalized eigenvalue problem (\ref{eq:BoundGenEig}), but to simplify the following discussion, I will refer to the set of matrices \textbf{H} and \textbf{S} as a single matrix. The diagrams in this section show a single matrix, but it is in actuality a pair of matrices forming the generalized eigenvalue problem.

\section{Linear Dependence in the Bound State Calculation}
With infinite precision in calculations, all terms from the basis set could be used. However, due to the limited precision inherent in computer calculations, when using large basis sets, near linear dependences will exist in the matrices. The goal is to identify and eliminate terms that exhibit near linear dependence with other terms. These terms are not exactly linearly dependent, if infinite precision was possible, but they are linearly dependent to computer precision.

To calculate the eigenvalues of the generalized eigenproblem, the LAPACK routine dsygv is used \cite{dsygv}. For the basis set consisting of terms from $\omega$ = 5, LAPACK computes the eigenvalues without errors. Adding in terms corresponding to $\omega = 6$ for some sets of nonlinear parameters causes dsygv to fail with an error set in the last parameter, Info. This error is always an integer greater than the number of terms, indicating from the library documentation that ``the leading minor of order i of B is not positive definite'' \cite{dsygv}. L\"uchow and Kleindienst also encountered a similar problem using NAG and EISPACK \cite{Luchow1993}.

This error does suggest that one approach to identifying problematic terms is to check for positive definiteness of the overlap matrix $\left\langle \phi | \phi \right\rangle$. This is one method that Yan et. al use to isolate problematic terms \cite{Yan1999}. They test the eigenvalues of the overlap matrix to see if any are small or negative, though there is no mention in their paper of what value of ``small'' is used. In several papers by Yan and others \cite{Yan1998,Yan1998a,Yan1999,Drake1995,Yan1997a}, terms with $j1 > j2$ are omitted if $l_1 = l_2$ and $\alpha \approx \beta$, along with $j_1 = j_2$ if $j_{23} > j_{31}$. No reasoning is given in these papers as to why these terms should cause near linear dependence or why they were chosen to be omitted. Right now, it is assumed that these terms were determined by trial and error or by noticing patterns in terms that produced near linear dependence.

As mentioned in the previous paragraph, the overlap matrix will no longer be positive-definite if a term is included in the basis set which introduces a near linear dependence. We attempted to use this fact to remove problematic terms, but too many terms were removed, leading to an energy that converged too slowly. This may need to be looked at again.

Another technique Yan et al.\ used was to partition the basis set into five sectors, each with a different set of nonlinear parameters and maximum $\omega$ \cite{Yan1999}. The sectors also have restrictions on the interparticle $r_{ij}$ terms, mainly limiting the power of $r_{23}$ and $r_{31}$, which are the electron-positron coordinates in their paper (corresponding to $r_{12}$ and $r_{13}$ in our work). The techniques used by Yan, Drake and Ho for restricting the set of terms are not used in our work.


\subsection{Allan Todd's Algorithm}
\label{sec:ToddBound}
In trying to determine the energy eigenvalues, we noticed that the ordering of the terms could determine whether there was linear dependence in the matrices. Allan Todd's algorithm was attractive, because it reorders the matrices to obtain the best possible energy, and it is a purely computational approach \cite{Todd2007}. So far, we have not seen any physical reason why certain terms should introduce a near linear dependence. A description of his algorithm as implemented by us follows.

The total number of terms to look at is $N = N(\omega)$ (see equation \ref{eq:NumberTermsOmega}). N matrices of size 1x1 are created for each term. This is done for the overlap and the $\left\langle \phi \left| \,H \right| \phi \right\rangle$ matrices together. The LAPACK dsygv routine is used to determine the lowest eigenvalue for each of these N sets. These energy eigenvalues are compared against one another, and the term with the lowest energy is chosen. In the next step, the first basis function from the previous step is combined with each unused term to create N-1 matrices of size 2x2. Again, the energy eigenvalues for each of the N-1 matrices are compared against each other, and the term yielding the lowest energy is chosen as the second basis function. This is done again with 3x3 matrices for each of the N-2 remaining terms combined with the basis functions chosen in the first two steps. This procedure is repeated until all terms have been used or the remaining terms are problematic.

In his original algorithm, Allan Todd looked at the eigenvalues computed from the upper and lower triangular matrices. Normally, the overlap and H matrices are symmetric, but this is not true to machine precision due to truncation and rounding. If the energy eigenvalues from the upper and lower triangles differ by more than $10^{-7}$ (in atomic units), the last added term is considered problematic and discarded.

In our testing for $\omega = 6$, no terms were omitted due to the reordering. As noted earlier, before implementing this algorithm, LAPACK would fail when trying to calculate the eigenvalues, so the ordering is important for getting the best possible energy. For $\omega$ = 7, 116 terms were omitted, out of a total of 1716 terms. The criteria that the eigenvalues for the upper and lower matrices differs by no more than a certain amount was not needed in this case. The Info parameter of the LAPACK dsygv function is checked for both the upper and lower matrix eigenvalue calculations, and the last added term is discarded if it causes an error due to linear dependence. When only the 116 problematic terms were left, every one of them caused LAPACK to error. If a term was problematic at any stage, it continued to be problematic in all further stages, so computation time can be decreased by immediately discarding it.

For larger basis sets, this algorithm becomes extremely slow, as determining the eigenvalues is an $O(N^3)$ operation. It can easily be parallelized, since we are computing the eigenvalues for a large number of matrices. Our program has been parallelized using OpenMP for intranode communications and Open MPI for internode communications. Todd's algorithm provides the best converged energy for a set of terms, albeit at a cost of computational speed.

\begin{figure}[H]
	\centering
	{\includegraphics[height=1.5in]{Todd}}
	\caption{Diagram of Todd's procedure}
	\label{fig:Todd}
\end{figure}


\subsection{L\"uchow and Kleindienst Algorithm} \label{sec:LuchowBound}
The algorithm that L\"uchow and Kleindienst propose \cite{Luchow1992} is similar to Todd's algorithm. They use all terms through $\omega = 5$, since none of these have linear dependence within this set. This fact could be applied to Allan Todd's algorithm to speed up the calculation. The rest of the terms are partitioned up into blocks of 300-400 terms, except the last block, which will have modulus(N - 462, block size) terms. A key difference from Allan Todd's algorithm is that the terms should be ordered in terms of increasing omega. In Allan Todd's algorithm, the initial ordering does not matter. The terms in the first block are added to the basis set for $\omega = 5$, which has 462 terms. If we use a block with 300 terms, then 300 matrices of size 463x463 are created, and their eigenvalues are determined. Whichever term gives the lowest energy when added to this set is saved to the basis set. This continues with ever-increasing matrix sizes, until all terms in the block are used, or a linear dependence is noticed. L\"uchow and Kleindienst propose that linear dependences can be prevented by omitting terms that do not contribute significantly to the energy. The energy from the previous step is saved, and the energy from the current step is compared to this. If the difference in energies is small, e.g. $\Delta E < 10^{-10} E_h$ in their paper, then that term is omitted. Since the lowest energy is chosen at each step, when this $\Delta E$ is too small, the rest of the block can be omitted.

Two parameters that are adjustable in this algorithm are the block size and cutoff value for the energy. To determine the best values for each, $\omega$ was set to a value of 7, and one of the parameters was held constant. To determine the optimal block size, an energy cutoff of $5\e{-9}$ was used.
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
Block size & Used terms & Energy & Time (min)\\
\hline
200 & 1041 & -0.7891818907 & 470 \\
250 & 1024 & -0.7891845001 & 572 \\
300 & 960 & -0.7891805208 & 749 \\
350 & 999 & -0.7891819425 & unknown \\
400 & 1012 & -0.7891855882 & 852 \\
500 & 985 & -0.7891841163 & 764 \\
\hline
\end{tabular}
\end{center}

For most trials, increasing the block size also increased the time it took to complete the computation. It can be seen that a block size of N-462 gives a modified version of Todd's algorithm, since we are testing all terms at each step. A block size of 1 would correspond to no reordering of terms, leading to including problematic terms. The cutoff value for $\Delta E$, $E_{\text{cutoff}}$, is $10^{-10} E_h$ in L\"uchow and Kleindienst's paper [8], but a value of $10^{-10}$ in our calculations led to LAPACK errors due to linear dependences. The block size was set to 400, and it was determined that an energy cutoff of $10^{-9}$ was the largest value that caused linear dependences.

\begin{center}
\begin{tabular}{|c|c|c|}
\hline
Energy cutoff & Used terms & Energy\\
\hline
2\e{-9} & 1116 & -0.789185858 \\
3\e{-9} & 1053 & -0.789186346 \\
4\e{-9} & 1043 & -0.789185173 \\
5\e{-9} & 1012 & -0.789185588 \\
1\e{-8} & 963 & -0.789188024 \\
\hline
\end{tabular}
\end{center}

Unfortunately, the intuition that a larger block size and smaller energy cutoff will yield a better final energy is not necessarily correct. The best value of the energy was actually obtained for the largest tested energy cutoff of $10^{-8}$. A block size of 500 also gave a worse energy than did a block size of 400. More tests need to be performed to determine the optimal value of both parameters, and these could possibly change for higher values of $\omega$ or for a different system.

We decided to use the Todd algorithm (\ref{sec:ToddBound}) due to the better energy obtained and the larger set of terms returned. The Todd algorithm is also more consistent between runs. The trade-off is the increased time to perform a calculation, especially for large $\omega$.

\begin{figure}[H]
	\centering
	{\includegraphics[height=2in]{Luchow}}
	\caption{Diagram of L\"uchow and Kleindienst procedure}
	\label{fig:Luchow}
\end{figure}



\section{Quadrature Points}
\label{sec:QuadraturePoints}
%\begin{lstlisting}[label=some-code,caption=Some Code]
\lstset{captionpos=b,frame=lines,numbers=left,basicstyle=\tiny,numberstyle=\tiny,numbersep=5pt,breaklines=true,showstringspaces=false,basicstyle=\footnotesize,emph={label}}
\begin{lstlisting}[caption=Base set of integration points in parameterfilepvr.txt]
Number of quadrature points for the various matrix elements

SLS: x, y, z, r3 Leg, r3 Lag, r13 Leg
45 35 35 35 28 15
SLS 2/r23 term: r1 Lag, r2 Leg, r2 Lag, r3 Leg, r3 Lag, phi12, r13 Leg, r23 Leg
65 35 28 35 28 12 15 15

CLS: x, y, z, r3 Leg, r3 Lag, r13 Leg
45 35 35 35 28 15
CLS 2/r23 term: r1 Lag, r2 Leg, r2 Lag, r3 Leg, r3 Lag, phi12, r13 Leg, r23 Leg
65 35 28 35 28 12 15 15

CLC: x, y, z, r3 Leg, r3 Lag, r13 Leg
45 35 35 35 28 15
CLC 2/r23 term: r1 Lag, r2 Leg, r2 Lag, r3 Leg, r3 Lag, phi12, r13 Leg, r23 Leg
65 35 28 35 28 12 15 15

PhiLS with qi = 0: r1 Lag, r2 Leg, r2 Lag, r3 Leg, r3 Lag, r12 Leg, r13 Leg
90 57 34 57 34 30 30
PhiLS 2/r23 term with qi = 0: r1 Lag, r2 Leg, r2 Lag, r3 Leg, r3 Lag, r12 Leg, phi13, r23 Leg
90 58 30 55 35 33 33 33
PhiLS full with qi > 0: r1 Lag, r2 Leg, r2 Lag, r3 Leg, r3 Lag, r12 Leg, r13 Leg, phi23
90 57 34 57 34 30 30 30
PhiLC with qi = 0: r1 Lag, r2 Leg, r2 Lag, r3 Leg, r3 Lag, r12 Leg, r13 Leg
90 57 34 57 34 30 30
PhiLC 2/r23 term with qi = 0: r1 Lag, r2 Leg, r2 Lag, r3 Leg, r3 Lag, r12 Leg, phi13, r23 Leg
90 58 30 55 35 33 33 33
PhiLC full with qi > 0: r1 Lag, r2 Leg, r2 Lag, r3 Leg, r3 Lag, r12 Leg, r13 Leg, phi23
90 57 34 57 34 30 30 30

r2 and r3 integration cusp unimportant
100.0
100.0
Nonlinear parameter mu
0.9
Positronium wavenumber kappa
0.1
Singlet or triplet (1 for singlet, -1 for triplet)
1
\end{lstlisting}


\begin{table}[H]
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline
 & Coord & Coord & Coord & Coord & Coord & Coord & Coord & Coord\\
Integral & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\
\hline
 Long-long, no $r_{23}^{-1}$ & 45 & 35 & 35 & 35 & 28 & 15 & & \\
 Long-long, $r_{23}^{-1}$ & 65 & 35 & 28 & 35 & 28 & 12 & 15 & 15 \\
\hline
 Long-short $q_i = 0$, no $r_{23}^{-1}$ & 90 & 57 & 34 & 57 & 34 & 30 & 30 & \\
 Long-short $q_i = 0$, $r_{23}^{-1}$ & 90 & 58 & 30 & 55 & 35 & 33 & 33 & 33 \\
 Long-short $q_i > 0$ & 90 & 57 & 34 & 57 & 34 & 30 & 30 & 30 \\
\hline
\end{tabular}
\caption{Base set of effective coordinates for S-wave integrations}
\label{tab:BaseEffectiveCoords}
\end{center}
\end{table}


\begin{table}[H]
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline
 & Coord & Coord & Coord & Coord & Coord & Coord & Coord & Coord\\
Integral & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\
\hline
 Long-long, no $r_{23}^{-1}$ & 55 & 40 & 40 & 40 & 38 & 25 & & \\
 Long-long, $r_{23}^{-1}$ & 75 & 40 & 33 & 40 & 38 & 22 & 25 & 25 \\
\hline
 Long-short $q_i = 0$, no $r_{23}^{-1}$ & 100 & 62 & 39 & 62 & 44 & 40 & 40 & \\
 Long-short $q_i = 0$, $r_{23}^{-1}$ & 100 & 63 & 34 & 60 & 45 & 43 & 43 & 43 \\
 Long-short $q_i > 0$ & 100 & 62 & 39 & 62 & 44 & 40 & 40 & 40 \\
\hline
\end{tabular}
\caption{Optimal set of effective coordinates for S-wave integrations}
\label{tab:OptimalEffectiveCoords}
\end{center}
\end{table}

Describing the number of points used in integrating the different coordinates in sections \ref{sec:LongLongInt} and \ref{sec:ShortLongInt} can be confusing, so we have taken to grouping the sets of points as in tables \ref{tab:BaseEffectiveCoords} and \ref{tab:OptimalEffectiveCoords}. Each column of this table is referred to as an ``effective coordinate''.



\begin{table}[H]
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline
 & Coord & Coord & Coord & Coord & Coord & Coord & Coord & Coord\\
Integral & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\
\hline
 Long-long, no $r_{23}^{-1}$ & $x$ Lag & $y$ Lag & $z$ Lag & $r_3$ Leg & $r_3$ Leg & $r_{13}$ Leg & & \\
 Long-long, $r_{23}^{-1}$ & $r_1$ Lag & $r_2$ Leg & $r_2$ Lag & $r_3$ Leg & $r_3$ Lag & $\phi_{12}$ Che & $r_{13}$ Leg & $r_{23}$ Leg \\
\hline
 Long-short $q_i = 0$, no $r_{23}^{-1}$ & $r_1$ Lag & $r_2$ Leg & $r_2$ Lag & $r_3$ Leg & $r_3$ Lag & $r_{12}$ Leg & $r_{13}$ Leg & \\
 Long-short $q_i = 0$, $r_{23}^{-1}$ & $r_1$ Lag & $r_2$ Leg & $r_2$ Lag & $r_3$ Leg & $r_3$ Lag & $r_{12}$ Leg & $\phi_{13}$ Che & $r_{23}$ Leg \\
 Long-short $q_i > 0$ & $r_1$ Lag & $r_2$ Leg & $r_2$ Lag & $r_3$ Leg & $r_3$ Lag & $r_{12}$ Leg & $r_{13}$ Leg & $\phi_{23}$ Che \\
\hline
\end{tabular}
\caption{Description of effective coordinates for S-wave integrations}
\label{tab:EffectiveCoords}
\end{center}
\end{table}


\section{Selection of Quadrature Points}
\label{sec:SelQuadPoints1}
The number of quadrature points for each coordinate in the 6-dimensional integrations is critical to have fully converged results. In our testing, the $r_1$ coordinate (the coordinate of $e^+$) was the most important, requiring more integration points than any other. The $r_2$ and $r_3$ coordinates were the second most important, and the interparticle terms ($r_{12}$, $r_{13}$ and $r_{23}$) were the least important. These results only apply to the long-range--long-range and long-range--short-range terms, as the short-range--short-range terms are integrated using the same asymptotic expansion method as the bound state problem (see section \ref{sec:SWaveShortShort}).

To determine this, we held the number of integration points fixed, except for one coordinate, which we increased in steps. The difference in the output between steps was used to analyze how important each coordinate was. Also, some terms are more sensitive to the number of integration points than other. For instance, the $(\bar{S},L\bar{S})$ term converges relatively quickly, while the $(\bar{C},L\bar{C})$ term requires more integration points.

We also used a sample input file from Van Reeth for the number of quadrature points he used in his code. In figure \ref{fig:OriginalPhaseShifts-pvr}, this set of points was used. After approximately 525 short-range terms, it is immediately apparent that the phase shifts diverge, with a particularly large deviation in the inverse Kohn output. The Kohn and complex Kohn methods converge again shortly before 600 terms and stay converged up to 1000 terms.

Adding 5 points to all integrations yields a much more well-behaved graph in figure \ref{fig:OriginalPhaseShifts-pvrplus5}. There are slight variations, one of which can be seen in the inset graph at about 540 terms, but the results are overall converged up to 1100 terms.

Increasing the number of points can have a huge impact on performance. Adding 5 points to an $\omega = 0$ calculation takes 3.5 hours, while adding 10 points makes it take 6.1 hours, or approximately twice the time. So we have to make a trade-off between accuracy and performance.

To determine an optimal set of points, 10 points were added to Van Reeth's set in all coordinates, and a run was done with this set. Then 5 points were subtracted from one coordinate from this set for each run, once for each coordinate. The difference in the matrix elements and phase shifts was small for the 2nd, 3rd and 4th coordinates. A final run using 5 points extra from Van Reeth's set for the 2nd, 3rd and 4th coordinates, along with 10 points extra in all other coordinates, showed small differences from the first set that had 10 points extra in all coordinates. Reducing the points of any of the other coordinates resulted in larger differences from the set with 10 extra points in all coordinates. This final set, referred to as the ``optimal set'', is used in all of our current runs. Increasing the number of integration points further than could potentially lead to better accuracy, though numerical instabilities start appearing with 15 extra points over the base set.


\begin{figure}[H]
	\centering
	\includegraphics[width=7in]{OriginalPhaseShifts-pvr}
	\caption{Phase shifts with original ordering $(\omega = 7)$}
	\label{fig:OriginalPhaseShifts-pvr}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=7in]{OriginalPhaseShifts-pvrplus5}
	\caption{Phase shifts with original ordering and 5 extra points $(\omega = 7)$}
	\label{fig:OriginalPhaseShifts-pvrplus5}
\end{figure}


\section{Phase Shift Convergence and Singularities}
Schwartz singularities are well-documented \cite{?} and are non-physical ``resonances''. To avoid these singularities, we use multiple forms of the Kohn method: Kohn, inverse Kohn, complex Kohn and the generalized Kohn. There may also be spurious results if the matrix elements are not converged, with one example being the feature at approximately 600 terms in figure \ref{fig:OriginalPhaseShifts-pvr} for the inverse Kohn. With the original ordering of the short-range terms, the phase shifts always break up at around 1100 terms, even when the matrix elements are converged. To alleviate this problem, we have implemented the Todd algorithm.

\section{Todd Algorithm Applied to the Scattering Problem}
\label{sec:ToddScattering}
From the bound state calculation using Todd's algorithm mentioned in section \ref{sec:ToddBound}, we know which short-range Hylleraas terms approximate the wavefunction of PsH best. We have observed that the short-range--short-range terms used in the same order as the output of the Todd algorithm will generate well-converged phase shifts. The separate code to determine the phase shifts uses the output from the bound state code. Again, the phase shift is plotted with respect to the number of short-range terms. The result is in figure \ref{fig:ToddPhaseShifts-pvrplus5}. The phase shifts are converged well until term 1216. A magnification of the graph in the small region around this term is provided in the inset graph.

At term 1216, the Kohn method result starts to diverge from the others. Shortly after term 1280, the five different methods for $\tau = 0.0 - 0.5$ start to diverge slightly. The differences here are very small (on the order of $10^{-5}$), unlike in figure \ref{fig:OriginalPhaseShifts-pvrplus5}. The jump in phase shifts seen in figure \ref{fig:OriginalPhaseShifts-pvrplus5} does not take place until much later and is not as large. Near 1650 terms, the phase shifts are not well converged, but they are also not as nearly ill-behaved as the results in figure \ref{fig:OriginalPhaseShifts-pvrplus5}.

\begin{figure}[H]
	\centering
	\includegraphics[width=7in]{ToddPhaseShifts-pvrplus5}
	\caption{Phase shifts with Todd terms and 5 extra points}
	\label{fig:ToddPhaseShifts-pvrplus5}
\end{figure}


\section{Todd Algorithm with Optimized Quadrature}


\begin{figure}[H]
	\centering
	\includegraphics[width=7in]{ToddOrderKohnPhaseShiftsOpt7}
	\caption{Phase shifts with Todd ordering and optimal set of points}
	\label{fig:ToddOrderKohnPhaseShiftsOpt7}
\end{figure}


\begin{figure}[H]
	\centering
	\includegraphics[width=7in]{ToddPhaseShifts-pvrbest}
	\caption{Phase shifts with resorted Todd terms and optimal set of points}
	\label{fig:ToddPhaseShifts-pvroptimized}
\end{figure}

Section \ref{sec:QuadraturePoints} has a discussion on the ``optimal set'' of quadrature points. When this optimal set is used with Todd's method, a very stable set of phase shifts is created. The graph in figure \ref{fig:ToddOrderKohnPhaseShiftsOpt7} shows how the phase shifts are well converged up to 1450 terms. At approximately term 1450, the phase shifts for the various Kohn methods begin to diverge. The Kohn results begin to diverge earlier than the other three variants in figure \ref{fig:ToddOrderKohnPhaseShiftsOpt7}. Notice that a similar behavior occurs in figure \ref{fig:ToddPhaseShifts-pvrplus5} at 1216 terms.

We have not developed an automated method of determining where this divergence occurs, so a visual inspection of the graph is needed. Graphs like the above are created in gnuplot, but we have developed a MATLAB script that makes this much easier. This script loads and plots data from all variations on the Kohn method, including the 35 values of $\tau$ for the generalized Kohn. MATLAB allows zooming of figures, so it is simple to find the term where the phase shifts begin to diverge.

For the extrapolation method discussed in section \ref{sec:Extrapolation}, it is useful to reorder the terms in the original ordering with increasing $\omega$. The first 1450 terms of figure \ref{fig:ToddOrderKohnPhaseShiftsOpt7} are used and then reordered, leading to the graph in figure \ref{fig:ToddPhaseShifts-pvroptimized}. There is a very small difference between the Kohn methods, but they do not diverge as in figure \ref{fig:ToddPhaseShifts-pvroptimized} after 1450 terms.



\section{Generalized Kohn}
\label{sec:CompGenKohn}
As mentioned in section \ref{sec:GenKohn}, the generalized Kohn method described by Cooper et al.\ allows for an adjustable parameter $\tau$ to be used. For our calculations of the Kohn and inverse Kohn, we set $\tau = 0$ and $\tau = \frac{\pi}{2}$, respectively. Before we started using the generalized Kohn method, it was difficult to tell if the difference between the Kohn and inverse Kohn phase shifts was due to a Schwartz singularity or a problem with linear dependence. With the generalized Kohn, we have a large number of individual Kohn methods to compare the results with.

The phase shift program steps through $\tau = 0$ to $\tau = 3.0$ in increments of $0.1$ for each N. There is also an additional modified phase shift program that steps through $\tau = 0.05$ to $\tau = 3.05$, also in increments of $0.1$, to get points in between the first set. The code can also be easily modified to use any value of $\tau$, which was used in figure \ref{fig:PhaseTau}.

The Kohn methods do not require a recalculation of the entire problem for each $\tau$. Once the original matrix equation (\ref{eq:KohnMatrix}) is calculated, along with the $(\bar{S},L\bar{S})$ term, the elements are reused to perform the other Kohn method calculations, as in (\ref{eq:ComplexKohnMatrix}) and (\ref{eq:GenKohnMatrix}).



\setlength{\abovecaptionskip}{0pt}   % 0.5cm as an example

\begin{figure}[H]
	\centering
	\includegraphics[width=7in]{PhaseTau}
	\caption{Phase shifts versus $\tau$ in the generalized Kohn method for $^1$S Ps-H scattering $(\omega = 7, \kappa = 0.1)$}
	\label{fig:PhaseTau}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=7in]{PhaseTau-Omega}
	\caption{Phase shifts versus $\tau$ for $\kappa = 0.1$ and varying $\omega$ values}
	\label{fig:PhaseTau-Omega}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=7in]{PhaseTau-Kappa}
	\caption{Phase shifts versus $\tau$ for $\omega = 7$ and varying $\kappa$ values}
	\label{fig:PhaseTau-Kappa}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=4in]{Det-Omega=6,Kappa=01}
	\caption{Determinant of $A$ versus $\tau$ for $\omega = 6$ with 875 terms of Todd reordering}
	\label{fig:Det-Omega=6,Kappa=01}
\end{figure}

The roots of $det(A)$ are at approximately $\tau = 0.125$ and $\tau = 1.144$. The first root corresponds well with the singularity in the $\omega = 6$ graph in figure \ref{fig:PhaseTau-Omega}. The second root is referred to as an ``anomaly-free singularity'' in Cooper et al.\ \cite{Cooper2009} and does not correspond to a Schwartz singularity. The roots are easily found by fitting the data to equation (20) and solving equation (21) in Cooper et al.\ \cite{Cooper2009}.


\section{Extrapolation}
\label{sec:Extrapolation}

\subsection{Extrapolation Description}

The tangent of the phase shifts is fitted to the function
\beq
\label{eq:PhaseExtrap}
\tan \delta^\pm(\omega) = \tan \delta^\pm(\omega = \infty) + \frac{c}{\omega^p}.
\eeq
\beq
\label{eq:PhaseExtrap2}
\lambda^\pm(\omega) = \lambda^\pm(\omega = \infty) + \frac{c}{\omega^p}
\eeq
The $c$ and $p$ in this equation are fitting parameters. When plotted with respect to $\omega^{-p}$, the tangents of the phase shifts form nearly a straight line, with the y-intercept being the tangent of the extrapolated value of the phase shift, $\tan(\delta^\pm(\omega = \infty))$.

In Van Reeth and Humberston, the extrapolation is done using $\omega = 3$ through $\omega = 6$ \cite{VanReeth2003}. Our results go to $\omega = 7$, so we have completed the extrapolation using the sets $\omega = 3-6$, $\omega = 3-7$ and $\omega = 4-7$. The smallest residuals are normally found with the set $\omega = 4-7$. Table \ref{tab:FittingParams} has the fitting parameters for the singlet and triplet S-wave states. These parameters are taken from the phase shifts determined by the S-matrix and T-matrix complex Kohn methods for $\omega = 4-7$. The values of the extrapolated phase shifts using this method are in table \ref{tab:SWavePhase}.

\begin{table}[H]
\begin{center}
\begin{tabular}{|c !{\vrule width 1pt} c|c !{\vrule width 1pt} c|c|}
\hline
$\kappa$ & $c^+$ & $p^+$ & $c^-$ & $p^-$ \\
\hline
0.1 & 0.308 & 2.89 & 0.760 & 3.75 \\
0.2 & 2.804 & 3.77 & 1.481 & 3.84 \\
0.3 & 36.32 & 4.76 & 1.876 & 3.59 \\
0.4 & 712.8 & 5.13 & 4.202 & 3.65 \\
0.5 & 257.8 & 4.14 & 9.937 & 3.60 \\
0.6 & 42.92 & 4.07 & 24.09 & 3.39 \\
0.7 & 27.70 & 4.02 & 219.6 & 3.81 \\
\hline
\end{tabular}
\caption{Fitting Parameters for Singlet (+) and Triplet (-)}
\label{tab:FittingParams}
\end{center}
\end{table}

\subsection{Reordering}
\textbf{@TODO:} Graphs of extrapolation for singlet/triplet and with/without reordering

As described in section \ref{sec:ToddScattering}, we omit certain terms using Todd's method. The output of this method from the bound state program described in section \ref{sec:ToddBound} is not ordered in terms of increasing $\omega$. This leads to difficulties when attempting to do the extrapolation in equation \ref{eq:PhaseExtrap}. The tangent of the phase shifts cannot be fitted to a straight line. The results of such an attempt can be seen in figure \ref{}. If we reorder the short-range terms back into their original order while still omitting terms, the tangent of the phase shifts can now be fitted to this straight line, as can be seen in figure \ref{}. The reordering does not affect the phase shifts in any case that we tested, since more terms are normally omitted in the scattering problem than just the bound state problem.

\subsection{Extrapolation Program}
We wrote a Python \cite{Python} program to extrapolate the phase shifts for a run for all Kohn method variants, including the 35 values of $\tau$ used in the generalized Kohn. The extrapolation is performed with a least-squares fitting using the polyfit function of the SciPy package \cite{SciPy}. This program can do the extrapolation over any interval of $\omega$ values requested. The extrapolations from the 39 total Kohn variants are compared to see if there is any large discrepancy between them, indicating numerical instability. The phase shift can have a singularity in the generalized Kohn method as seen in figure \ref{fig:PhaseTau}, so care must be taken to ensure extrapolations are not taken around this interval.


\section{Cusps}
\textbf{@TODO:} Discussion about the existence of the cusps in the integrand, possibly with graphs illustrating them.

For the S-wave, all runs were performed with the cusp parameters set at $r_1 = 100$. When $r_1 > 100$, the $r_2$ and $r_3$ integrations are done using only Gauss-Laguerre, since the cusp is considered unimportant at that distance. When $r_1 \leq 100$, we use Gauss-Legendre before the cusp and Gauss-Laguerre after the cusp, as described in sections \ref{sec:LongLongNoR23} and \ref{sec:LongLongR23}. 

Van Reeth used cusp parameters set at $r_1 = 25$, with little apparent loss of precision over using $r_1 = 100$ \cite{}. With $\kappa$ set at $0.1$, several tests were performed with different cusp parameters. With cusp parameters of 100, for $\omega = 6$, we are able to use 910 terms, giving a phase shift of $-0.427$. Doing the same run with cusp parameters of 25 allows us to use the same number of terms and gives a phase shift of $-0.427$ as well. In this particular example, the two sets of cusp parameters (25 and 100) differ in the sixth decimal place. As an example, for the inverse Kohn, $\delta = -0.42707291$ for the cusp parameters of 100, while $\delta = -0.42707370$ for cusp parameters of 25. To the required accuracy, the cusp parameters of 25 are sufficient for this example.

Smaller values for these cusp parameters were also tried, and these tests are summarized in table \ref{tab:SWaveCuspParameters}. When the cusp parameters are too small, such as the cases of 5, 10 and 15, the phase shifts do not converge well and start to diverge much earlier. The second column in this table shows the number of terms we can use for each set, but the number of terms to use is not exact due to the lack of good convergence, so the values here are approximate for small cusp parameters. The phase shift given for these three tests are therefore approximate as well. From this table, we conclude that 20 is the minimum value needed, at least for the $\kappa = 0.1$ case tested here for the S-wave. To be conservative, future runs will use cusp parameters of 25. Further testing with other $\kappa$ values should be performed to verify that these results hold for higher momenta.

\begin{table}[H]
\begin{center}
\begin{tabular}{c c c}
\toprule
Cusp parameter & Terms possible & Phase shift \\
\midrule
 5 & 531 & -0.4281 \\
10 & 684 & -0.4071 \\
15 & 684 & -0.4267 \\
20 & 910 & -0.4271 \\
25 & 910 & -0.4271 \\
100 & 910 & -0.4271 \\
\bottomrule
\end{tabular}
\caption{S-Wave Cusp Parameters}
\label{tab:SWaveCuspParameters}
\end{center}
\end{table}


\section{Selection of Quadrature Points}
\label{sec:SelQuadPoints2}

\begin{figure}[H]
	\resizebox{1.0\textwidth}{!}{\includegraphics{QuadPoints/ColorKey.pdf}}
	\caption{Color key for differences}
	\label{fig:ColorKey}
\end{figure}

For the P-wave, we noticed that the phase shifts for smaller $\kappa$ values were more sensitive to the number of integration points than higher $\kappa$ values. In general, the smaller the value of $\kappa$, the smaller the phase shift will be. The smaller phase shifts for the P-wave also caused it to be more sensitive than the S-wave.

\subsection{Comparison Program}
We wrote the program \emph{Comparison} to visually compare two runs with different numbers of integration points. This program calculates the relative difference between similar matrix elements of the two input files. The relative difference is given by
\beq
diff_{rel} = \left| \frac{elem_1 - elem_2}{(elem_1 + elem_2) / 2} \right|.
\eeq
Since the values of matrix elements can range over many orders of magnitude, the relative difference is an appropriate measure of the change caused by varying the number of integration points. The other option would have been to use the absolute difference, which is given by 
\beq
diff_{abs} = \left| elem_1 - elem_2 \right|.
\eeq
However, this is a poor measure of the differences, and the relative differences give much more useful information for our purposes.

The \emph{Comparison} program calculates these relative differences for each matrix element between the two input files and creates an image using the colors in figure \ref{fig:ColorKey}. So if a column of pixels in the output image is yellow, then the relative difference for that matrix element is on the order of $10^{-6}$. This is an example image from running this program:
\begin{figure}[H]
	\centering
	\resizebox{0.8\textwidth}{!}{\includegraphics{QuadPoints/Example.png}}
	\caption{Example matrix element comparison image}
	\label{fig:QuadExample}
\end{figure}
This only looks at the output from the long-range programs, and this is the first row (or column) of the $A$ matrix. The \emph{Comparison} program outputs a vertical line for each matrix element to make them more visible than outputting a single pixel. More examples and descriptions of the command line syntax are available on the \htmladdnormallink{Wiki}{http://cas-bs5cph1.phys.unt.edu/wiki/index.php/Long-range_graphical_comparison_program}.

\subsection{Application to the P-Wave}

Using the comparison program, we found that the $1/r_{23}$ term in the potential needed more integration points when $q_i = 0$. The integrations for the other three potential terms already produced reasonably converged results. All runs in this section are performed with $\kappa = 0.1$.

If we took the set of integration points that we used in the S-wave problem as our base set, then compared this with the same set but an extra 5 points in the $1^{st}$ coordinate, the resulting difference image for the $A$ matrix looks like this:
\begin{figure}[H]
	\centering
	\resizebox{1.0\textwidth}{!}{\includegraphics{QuadPoints/BasevsBaseplus5.png}}
	\caption{Base set versus base set plus 5 in $r_1$}
	\label{fig:BasevsBaseplus5}
\end{figure}
\noindent Notice that there is little blue and plenty of yellows, oranges and reds. The goal is to get as much black and blue as possible, though it is impossible to get entirely black and blue with our limited precision. It is evident that the matrix elements are not well-converged when we compare the phase shifts from these two runs. For the first run with the base set, the phase shift is 0.02346176. The corresponding phase shift for the second run is 0.02294583. We desire three significant figures in our phase shifts, so this is certainly not good enough.

Doing a similar run with the base set and another with the base set plus 10 in $r_1$, the difference image is given by figure \ref{fig:BasevsBaseplus10}.
\begin{figure}[H]
	\centering
	\resizebox{1.0\textwidth}{!}{\includegraphics{QuadPoints/BasevsBaseplus10.png}}
	\caption{Base set versus base set plus 10 in $r_1$}
	\label{fig:BasevsBaseplus10}
\end{figure}
\noindent This image is not much different from the previous image. Even when we compare the ``plus 5'' run with the ``plus 10'' run \textbf{@TODO: Where is this image?}, the image does not change much. The phase shift for the ``plus 10'' run is 0.02257283, which is still significantly different from the ``plus 5'' run.

We tried adding up to 25 extra points to the $1^{st}$ coordinate of the base set, but the matrix elements (and consequently, the phase shifts) still did not converge well enough. To perform the Gauss-Laguerre and Gauss-Legendre quadratures described in section \ref{sec:GaussQuad}, we have to compute the abscissae and weights for the Laguerre and Legendre polynomials. The weights depend on the abscissae, and the abscissae depend only on $n$, the number of quadrature points to use. This allows us to hardcode values for the abscissae and weights to speed up computations marginally. Previously, the long-range code used hardcoded values for some multiples of 5 but not all that were used. This code also did not have values hardcoded when the value of $n$ was not a multiple of 5. The integration points were then changed to use values that were multiples of 5, and all were hardcoded. The hardcoded values were also done in extended precision by using \emph{Mathematica}.

Figure \ref{fig:Base5vsBase5hardcoderound} shows the changes going from a previous ``plus 5'' run to a ``plus 5'' run with all hardcoded abscissae and weights. There is a relatively large difference in the matrix elements by making this change.
\begin{figure}[H]
	\centering
	\resizebox{1.0\textwidth}{!}{\includegraphics{QuadPoints/Base5vsBase5hardcoderound.png}}
	\caption{Changes going to hardcoded abscissae and weights}
	\label{fig:Base5vsBase5hardcoderound}
\end{figure}

The results were much better for the base set versus the ``plus 5'' set when hardcoded values for the abscissae and weight were used. Figure \ref{fig:BasehardcodevsBase5hardcode} shows this comparison, which has the large sections of black. All black and dark blue values are for terms where $q_i > 0$. This integration is done separately, as discussed in section \ref{sec:Swaveqigt0} for the S-wave.
\begin{figure}[H]
	\centering
	\resizebox{1.0\textwidth}{!}{\includegraphics{QuadPoints/BasehardcodevsBase5hardcode.png}}
	\caption{Base set with hardcoded values versus base set plus 5 with hardcoded values}
	\label{fig:BasehardcodevsBase5hardcode}
\end{figure}

We then completed a series of runs where we increased the number of integration points for each coordinate for $\omega = 2$. Figure \ref{fig:PlusCoord1-d} shows that the $1/r_{23}$ integration needs an extra 15 points in the first coordinate. The runs for the other coordinates were all performed with an extra 15 points in the first coordinate as well. From figures \ref{fig:PlusCoord2} through \ref{fig:PlusCoord8}, we see that the $5^{th}$ through $8^{th}$ coordinates possibly need more integration points.

\begin{figure}[H]
\centering
\subfloat[Part 1][Base vs. plus 5]{\includegraphics[height=1.2in]{QuadPoints/R23-BasevsBaseplus5-1st.png} \label{fig:PlusCoord1-a}}
\subfloat[Part 2][Plus 5 vs. plus 10]{\includegraphics[height=1.2in]{QuadPoints/R23-Baseplus5vsBaseplus10-1st.png} \label{fig:PlusCoord1-b}}
\subfloat[Part 3][Plus 10 vs. plus 15]{\includegraphics[height=1.2in]{QuadPoints/R23-Baseplus10vsBaseplus15-1st.png} \label{fig:PlusCoord1-c}}
\subfloat[Part 4][Plus 15 vs. plus 20]{\includegraphics[height=1.2in]{QuadPoints/R23-Baseplus15vsBaseplus20-1st.png} \label{fig:PlusCoord1-d}}
\caption{Comparison of extra points in $1^{st}$ coordinate after hardcoded abscissae}
\label{fig:PlusCoord1}
\end{figure}

\begin{figure}[H]
\centering
\subfloat[Part 1][Plus 5 vs. plus 10]{\includegraphics[height=0.8in]{QuadPoints/r23-2nd-plus5vsplus10.png} \label{fig:PlusCoord2-a}}
\subfloat[Part 2][Plus 10 vs. plus 15]{\includegraphics[height=0.8in]{QuadPoints/r23-2nd-plus5vsplus10.png} \label{fig:PlusCoord2-b}}
\subfloat[Part 3][Plus 15 vs. plus 20]{\includegraphics[height=0.8in]{QuadPoints/r23-2nd-plus5vsplus10.png} \label{fig:PlusCoord2-c}}
\caption{Comparison of extra points in $2^{nd}$ coordinate after hardcoded abscissae}
\label{fig:PlusCoord2}
\end{figure}

\begin{figure}[H]
\centering
\subfloat[Part 1][Plus 5 vs. plus 10]{\includegraphics[height=0.8in]{QuadPoints/r23-3rd-plus5vsplus10.png} \label{fig:PlusCoord3-a}}
\subfloat[Part 2][Plus 10 vs. plus 15]{\includegraphics[height=0.8in]{QuadPoints/r23-3rd-plus5vsplus10.png} \label{fig:PlusCoord3-b}}
\subfloat[Part 3][Plus 15 vs. plus 20]{\includegraphics[height=0.8in]{QuadPoints/r23-3rd-plus5vsplus10.png} \label{fig:PlusCoord3-c}}
\caption{Comparison of extra points in $3^{rd}$ coordinate after hardcoded abscissae}
\label{fig:PlusCoord3}
\end{figure}

\begin{figure}[H]
\centering
\subfloat[Part 1][Plus 5 vs. plus 10]{\includegraphics[height=0.8in]{QuadPoints/r23-4th-plus5vsplus10.png} \label{fig:PlusCoord4-a}}
\caption{Comparison of extra points in $4^{th}$ coordinate after hardcoded abscissae}
\label{fig:PlusCoord4}
\end{figure}

\begin{figure}[H]
\centering
\subfloat[Part 1][Plus 5 vs. plus 10]{\includegraphics[height=0.8in]{QuadPoints/r23-5th-plus5vsplus10.png} \label{fig:PlusCoord5-a}}
\subfloat[Part 2][Plus 10 vs. plus 15]{\includegraphics[height=0.8in]{QuadPoints/r23-5th-plus5vsplus10.png} \label{fig:PlusCoord5-b}}
\subfloat[Part 3][Plus 15 vs. plus 20]{\includegraphics[height=0.8in]{QuadPoints/r23-5th-plus5vsplus10.png} \label{fig:PlusCoord5-c}}
\caption{Comparison of extra points in $5^{th}$ coordinate after hardcoded abscissae}
\label{fig:PlusCoord5}
\end{figure}

\begin{figure}[H]
\centering
\subfloat[Part 1][Plus 5 vs. plus 10]{\includegraphics[height=0.8in]{QuadPoints/r23-6th-plus5vsplus10.png} \label{fig:PlusCoord6-a}}
\subfloat[Part 2][Plus 10 vs. plus 15]{\includegraphics[height=0.8in]{QuadPoints/r23-6th-plus5vsplus10.png} \label{fig:PlusCoord6-b}}
\subfloat[Part 3][Plus 15 vs. plus 20]{\includegraphics[height=0.8in]{QuadPoints/r23-6th-plus5vsplus10.png} \label{fig:PlusCoord6-c}}
\caption{Comparison of extra points in $6^{th}$ coordinate after hardcoded abscissae}
\label{fig:PlusCoord6}
\end{figure}

\begin{figure}[H]
\centering
\subfloat[Part 1][Plus 5 vs. plus 10]{\includegraphics[height=0.8in]{QuadPoints/r23-7th-plus5vsplus10.png} \label{fig:PlusCoord7-a}}
\subfloat[Part 2][Plus 10 vs. plus 15]{\includegraphics[height=0.8in]{QuadPoints/r23-7th-plus5vsplus10.png} \label{fig:PlusCoord7-b}}
\subfloat[Part 3][Plus 15 vs. plus 20]{\includegraphics[height=0.8in]{QuadPoints/r23-7th-plus5vsplus10.png} \label{fig:PlusCoord7-c}}
\caption{Comparison of extra points in $7^{th}$ coordinate after hardcoded abscissae}
\label{fig:PlusCoord7}
\end{figure}

\begin{figure}[H]
\centering
\subfloat[Part 1][Plus 5 vs. plus 10]{\includegraphics[height=0.8in]{QuadPoints/r23-8th-plus5vsplus10.png} \label{fig:PlusCoord8-a}}
\subfloat[Part 2][Plus 10 vs. plus 15]{\includegraphics[height=0.8in]{QuadPoints/r23-8th-plus5vsplus10.png} \label{fig:PlusCoord8-b}}
\subfloat[Part 3][Plus 15 vs. plus 20]{\includegraphics[height=0.8in]{QuadPoints/r23-8th-plus5vsplus10.png} \label{fig:PlusCoord8-c}}
\caption{Comparison of extra points in $8^{th}$ coordinate after hardcoded abscissae}
\label{fig:PlusCoord8}
\end{figure}

These tests give us an idea of what coordinates need more integration points. The phase shifts, not the matrix elements, are what we are concerned with, so we ran a number of tests for the phase shifts for $\omega = 6$. Table \ref{tab:5thcoordExtraPoints} shows how the phase shift stabilizes when the $5^{th}$ coordinate has an extra 10-15 points. For table \ref{tab:678thcoordExtraPoints}, we have 15 extra points in the $1^{st}$ and $5^{th}$ coordinates, then add points to all of the $6^{th}$, $7^{th}$ and $8^{th}$ coordinates simultaneously. To the required precision (3 significant figures), the phase shift does not change with this last set of changes. From these runs, we finally determined that the $1^{st}$ and $5^{th}$ coordinates needed 15 extra integration points each, and we can save adding extra points to the other coordinates.

\begin{table}[H]
\begin{center}
\begin{tabular}{c c}
\toprule
Extra points & Phase shift \\
\midrule
+5 & 0.02273585 \\
+10 & 0.02256803 \\
+15 & 0.02257100 \\
+20 & 0.02258546 \\
+25 & 0.02257720 \\
+30 & 0.02257869 \\
+35 & 0.02257844 \\
\bottomrule
\end{tabular}
\caption{5th Coordinate Comparisons}
\label{tab:5thcoordExtraPoints}
\end{center}
\end{table}


\begin{table}[H]
\begin{center}
\begin{tabular}{c c}
\toprule
Extra points & Phase shift \\
\midrule
+5 & 0.02255816 \\
+10 & 0.02255351 \\
+15 & 0.02255181 \\
\bottomrule
\end{tabular}
\caption{Extra points in the $6^{th}$, $7^{th}$ and $8^{th}$ coordinates}
\label{tab:678thcoordExtraPoints}
\end{center}
\end{table}

\textbf{@TODO: Table of final integration points}


\end{document}