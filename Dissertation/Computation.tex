% -*- root: Dissertation.tex -*-
\documentclass[Dissertation.tex]{subfiles} 
\begin{document}


\chapter{Computation}
\label{chp:Computation}

\iftoggle{UNT}{This}{\lettrine{\textcolor{startcolor}{T}}{his}}
chapter covers some of the major
computational details of this work. For additional details, such as resonance
fittings, determination of nonlinear parameters and the use of Gaussian
quadratures, refer to \cref{chp:ExtraNumerics}.

\section{Short-Range Terms}
\label{sec:CompShort}

Matrix elements in \cref{eq:GeneralKohnMatrix} involving only short-range 
terms are handled differently than those that involve long-range terms
(short-long and long-long). The integrals resulting from using
\Cref{eq:BoundHFull,eq:GradGradShort} in \cref{eq:GeneralKohnMatrix} are 
handled in this section.

The bound state problem is a generalized eigenvalue problem (see
\cref{eq:BoundGenEig}), but to simplify the following discussion, I will refer
to the set of matrices \textbf{H} and \textbf{S} as a single matrix. The 
diagrams in this section show a single matrix, but it is in actuality a pair 
of matrices forming the generalized eigenvalue problem.


\subsection{Short-Range -- Short-Range Integrations}
\label{sec:ShortInt}
The short-range--short-range (short-short) matrix elements make up the
bulk of the $\textbf{\emph{A}}$ matrix
(\cref{eq:GenKohnMatrixAXB}). The PsH bound state problem in 
\cref{chp:PsHBound} consists of only these types of matrix elements
(see \cref{eq:BoundWavefn}). The form of these short-range integrals is
\beq
\label{eq:FourBody}
I \equiv I(k_i, l_i, m_i, n_i, p_i, q_i; \bar{\alpha}, \bar{\beta}, \bar{\gamma}) = \int e^{-(\bar{\alpha} r_1 + \bar{\beta} r_2 + \bar{\gamma} r_3)} r_1^{k_i} r_2^{l_i} r_{12}^{m_i} r_3^{n_i} r_{13}^{p_i} r_{23}^{q_i} d\textbf{r}_1 d\textbf{r}_2 d\textbf{r}_3,
\eeq
with real-valued $\bar{\alpha}, \bar{\beta}, \bar{\gamma} > 0$. The $\bar{\alpha}$ is related
to $\alpha$ through \cref{eq:GeneralKohnMatrix}, as are the relations of the other
nonlinear parameters $\bar{\beta}$, $\beta$, $\bar{\gamma}$, and $\gamma$.

This class of integrals, the Hylleraas three-electron or four-body 
integrals, has been studied extensively. See
Refs.~\cite{Drake1995,Frolov2003,Pelzl1998,Ruiz2009,Pachucki2004} for just some of 
the papers detailing strategies on how to compute these integrals. The first 
three papers here use the same infinite summation to numerically solve this 
integral but use different techniques to accelerate the convergence, as the 
summation converges slowly for some arguments. The last paper by Pachucki et 
al.\ uses a very different approach with recursion relations, described in 
\cref{sec:RecursionRelations}.

Each of these methods has some restriction on how singular these integrals 
can be. For Drake and Yan's asymptotic expansion \cite{Drake1995,Yan1997},
$k_i, l_i, n_i \geq -2$ and $m_i, p_i, q_i \geq -1$. Yan extends these to
$k_i, l_i, m_i, n_i, p_i, q_i \geq -3$ in an additional paper \cite{Yan2000a}. For 
the recursion relations of Pachucki et al.\ \cite{Pachucki2004},
$k_i, l_i, m_i, n_i, p_i, q_i \geq -1$. Pachucki and Puchalski have two other papers,
one extending this to $k_i, l_i, m_i, n_i, p_i, q_i \geq -2$ \cite{Pachucki2005} 
and another even extending these to $k_i, l_i, m_i, n_i, p_i, q_i \geq -3$ 
\cite{Pachucki2008}. Our work for the D-wave has some terms with $k_i$, $l_i$,
or $n_i = -2$, restricting what methods we can use. The biggest need for 
integrals more singular than $\frac{1}{r_i}$ or $\frac{1}{r_{ij}}$ in most 
work (such as lithium energies \cite{Yan1997a,Puchalski2010}) is for 
relativistic or quantum electrodynamics effects
\cite{Yan1997,Pachucki2008,Puchalski2010}.

{\"O}hrn and Nordling \cite{Ohrn1963} were the first to give a method to 
solve this type of integral by splitting it into summations over $W$ 
functions. To deal with odd powers of $r_{ij}$, these terms are usually 
expanded in a Laplace expansion using Perkins's expression \cite{Perkins1968}.
A related expression is given by Sack \cite{Sack1964}. Porras and King
\cite{Porras1994} also use another expansion with Gegenbauer polynomials.

From Drake and Yan's paper \cite{Drake1995}, splitting into $W$ functions gives
\begin{align}
\label{eq:FourBodyExpansion}
I &= (4\pi)^3 \sum_{q=0}^\infty \sum_{k_{12} = 0}^{L_{12}} \sum_{k_{12} = 0}^{L_{23}} \sum_{k_{12} = 0}^{L_{13}} \frac{1}{(2q+1)^2} C_{j_{12} q k_{12}} C_{j_{23} q k_{23}} C_{j_{13} q k_{13}} \nonumber \\
& \times [W(\tilde{k}_i + 2q + 2 k_{12} + 2 k_{13}, \tilde{l}_i + m_i - 2 k_{12} + 2 k_{23}, \tilde{n}_i + q_i - 2 q - 2 k_{23} + p_i - 2 k_{13}; \alpha, \beta, \gamma) \nonumber \\
      & + W(\tilde{k}_i + 2q + 2 k_{12} + 2 k_{13}, \tilde{n}_i + p_i - 2 k_{13} + 2 k_{23}, \tilde{l}_i + m_i - 2 q - 2 k_{23} + q_i - 2 k_{13}; \alpha, \gamma, \beta) \nonumber \\
      & + W(\tilde{l}_i + 2q + 2 k_{12} + 2 k_{23}, \tilde{k}_i + m_i - 2 k_{12} + 2 k_{13}, \tilde{n}_i + q_i - 2 q - 2 k_{23} + p_i - 2 k_{13}; \beta, \alpha, \gamma) \nonumber \\
      & + W(\tilde{l}_i + 2q + 2 k_{12} + 2 k_{23}, \tilde{n}_i + q_i - 2 k_{23} + 2 k_{13}, \tilde{k}_i + m_i - 2 q - 2 k_{23} + p_i - 2 k_{13}; \beta, \gamma, \alpha) \nonumber \\
      & + W(\tilde{n}_i + 2q + 2 k_{23} + 2 k_{13}, \tilde{k}_i + p_i - 2 k_{13} + 2 k_{12}, \tilde{l}_i + m_i - 2 q - 2 k_{23} + q_i - 2 k_{13}; \gamma, \alpha, \beta) \nonumber \\
      & + W(\tilde{n}_i + 2q + 2 k_{23} + 2 k_{13}, \tilde{l}_i + q_i - 2 k_{23} + 2 k_{12}, \tilde{k}_i + m_i - 2 q - 2 k_{23} + p_i - 2 k_{13}; \gamma, \beta, \alpha)].
\end{align}
The $C_{jqk}$ coefficients are given by Perkins \cite{Perkins1968} as
\beq
\label{eq:Ccoeff}
C_{jqk} = \frac{2q+1}{j+2} \Binomial{j+2}{2k+1} \prod_{t=0}^{\min{(q-1),\frac{1}{2}(j+1)}} \frac{2k+2t-j}{2k+2q-2t+1}.
\eeq
The $W$ functions are expressed as an infinite summation of the $_2F_1$ hypergeometric functions \cite{Drake1995}:
\begin{align}
\label{eq:Wfunc}
W(l,m,n;\alpha,\beta,\gamma) = &\frac{\Factorial{l}}{(\alpha+\beta+\gamma)^{l+m+n+3}} \sum_{p=0}^\infty \frac{\Factorial{(l+m+n+p+2)}}{\Factorial{(l+1+p)} (l+m+2+p)} \left( \frac{\alpha}{\alpha+\beta+\gamma} \right)^p  \nonumber \\
& \times \Hypergeometric{2}{1}{1,l+m+n+p+3}{l+m+p+3}{\frac{\alpha+\beta}{\alpha+\beta+\gamma}}.
\end{align}
To reduce computation time, we also use the recursion relation in their paper of
\beq
\Hypergeometric{2}{1}{1,a}{c}{z} = 1 + \left( \frac{a}{c} \right) z \,\, \Hypergeometric{2}{1}{1,a+1}{c+1}{z}.
\eeq
A derivation of this is given in \cref{sec:Hypergeometric}.

The $k_{ij}$ summations in \cref{eq:FourBodyExpansion} are all finite. If all powers of $r_{ij}$ are odd, the $q$ summation is infinite, and if any of $r_{ij}$ is even, the $q$ summation becomes finite. For the finite $q$ sums, these direct sums are solved very accurately, but for the infinite sums, some integrals converge slowly. Particularly when all three $r_{ij}$ powers are odd and at least one is $-1$, the integrals converge the slowest. It is possible to restrict the basis set described by \cref{eq:OmegaDef} so that at least one of the $r_{ij}$ powers is even, making solving the integrals easier. However, this leads to slow convergence in the energy \cite{Drake1995}.

As Frolov and Bailey \cite{Frolov2003} note, these four-body integrals only work for systems with one infinitely heavy particle, such as PsH or Ps-H scattering. For systems with arbitrary masses, such as Ps$_2$ or Ps-Ps scattering, this has to be generalized to
\beq
\label{eq:FourBodyIntGen}
I = \int e^{-(\bar{\alpha} r_1 + \bar{\beta} r_2 + \bar{\gamma} r_3 + a_{12} r_{12} + a_{13} r_{13} + a_{23} r_{23})} r_1^{k_i} r_2^{l_i} r_{12}^{m_i} r_3^{n_i} r_{13}^{p_i} r_{23}^{q_i} d\textbf{r}_1 d\textbf{r}_2 d\textbf{r}_3.
\eeq
Fromm and Hill give an analytic solution to this \cite{Fromm1987}, but it is extremely difficult to work with. Harris more recently solved this problem analytically using recursion relations \cite{Harris2009}, using a similar method to the recursion relations of Pachucki et al.\ \cite{Pachucki2004}. Both of these solutions restrict the powers of $r_i$ and $r_{ij}$ to $k_i, l_i, m_i, n_i, p_i, q_i \geq -1$. We have also looked at a subset of these integrals. %(refer to \cref{chp:Unfinished}).
As another extension of the Hylleraas basis set, some four-electron integrals can be reduced down to the three-electron integrals \cite{King1993,Pelzl2002}.


\subsubsection{Asymptotic Expansion}
\label{sec:AsymptoticExpansion}
For cases of \cref{eq:FourBodyExpansion} with all odd powers of $r_{ij}$, the $q$ summation is infinite, and the summation converges slowly. The convergence accelerator approach of Pelzl and King \cite{Pelzl1998,Pelzl2002} is one way to deal with this. I did limited testing with this approach but chose to instead use the asymptotic expansion method of Drake and Yan \cite{Drake1995}. In my testing, it was more numerically stable, and it has been generalized to arbitrary angular momenta \cite{Yan1997}.

As an example in Drake and Yan's paper \cite{Drake1995}, direct calculation of the $q$ summation for $I(0,0,0,-1,-1,-1; 1,1,1)$ only reaches an accuracy of $1.5 x 10^{-13}$ after 6860 terms. With their asymptotic expansion method, the integral has converged to approximately $2.2 x 10^{-16}$ after only 21 terms. The summation converges monotonically and asymptotically. Drake and Yan use this knowledge to speed up the convergence of the integration. Details of this method can be found in their paper \cite{Drake1995}.

I use this asymptotic expansion method in all calculations of the short--short integrals through the H-wave, and it performed very well. In fact, my quadruple precision code often calculates matrix elements to better than $1$ part in $10^{20}$ for the S-wave. \Cref{tab:AsympExpan} gives an example of the convergence of a single integral by only calculating the direct sum of \cref{eq:FourBodyExpansion} in the $S_d(N)$ column and with the asymptotic expansion in the $S_a(N)$ column. These four-body integrals are relatively quick to calculate, and most of the runs to compute them complete in a matter of hours.

\begin{table}
\centering
\begin{tabular}{c c c c}
\toprule
$N$ & $S_d(N)$ & $\Delta S_d(N)$ & $S_a(N)$ \\
\midrule
17 & 684.106 432 091 &               & 684.113 411 842 629 912 374 349 \\
18 & 684.107 475 306 & 0.001 043 214 & 684.113 411 842 629 911 836 645 \\
19 & 684.108 320 637 & 0.000 845 331 & 684.113 411 842 629 911 829 661 \\
20 & 684.109 012 851 & 0.000 692 213 & 684.113 411 842 629 911 835 071 \\
21 & 684.109 585 093 & 0.000 572 241 & 684.113 411 842 629 911 836 095 \\
22 & 684.110 062 261 & 0.000 477 167 & 684.113 411 842 629 911 836 195 \\
23 & 684.110 463 302 & 0.000 401 041 & 684.113 411 842 629 911 836 186 \\
24 & 684.110 802 809 & 0.000 339 506 & 684.113 411 842 629 911 836 178 \\
25 & 684.111 092 142 & 0.000 289 333 & 684.113 411 842 629 911 836 174 \\
26 & 684.111 340 236 & 0.000 248 094 & 684.113 411 842 629 911 836 173 \\
27 & 684.111 554 183 & 0.000 213 946 & 684.113 411 842 629 911 836 172 \\
28 & 684.111 739 660 & 0.000 185 477 & 684.113 411 842 629 911 836 172 \\
29 & 684.111 901 249 & 0.000 161 588 & 684.113 411 842 629 911 836 172 \\
30 & 684.112 042 674 & 0.000 141 425 & 684.113 411 842 629 911 836 172 \\
\bottomrule
\end{tabular}
\caption[Convergence of direct sum against the asymptotic expansion]
{Convergence of direct sum, $S_d(N)$, against the 
asymptotic expansion, $S_a(N)$. This is an extension of Table I in Drake and 
Yan's work \cite{Drake1995} and uses $\Lambda = 15$. $\Delta S_d(N)$ gives 
the difference between successive direct sums.}
\label{tab:AsympExpan}
\end{table}

\subsubsection{Recursion Relations}
\label{sec:RecursionRelations}
After the S-wave calculations were completed, we learned of an analytic, 
instead of numerical, solution to these three-electron integrals, derived by 
Pachucki et al.\ \cite{Pachucki2004}. They
were not the first to derive an analytic solution to the three-electron 
integrals, but the first by Fromm and Hill \cite{Fromm1987} is not very 
practical to use, considering its very complicated form. Each set of $r_i$ 
and $r_{ij}$ powers requires a new rederivation from the Fromm and Hill 
result. The recursion relations from Pachucki et al.\ are complicated but also general.

Like many other types of recursion relations, these recursion relations may 
not be stable for higher $\omega$ values, depending on the calculated 
precision. I have tested through $\omega = 8$, and this method produced 
stable results under quadruple precision. In some of their work on Li and
Be$^+$, their group uses sextuple precision, as quadruple precision becomes 
insufficient near $\omega = 10$ \cite{Puchalski2006}, which is much higher 
than we can use in the Ps-H scattering calculations.

These are used as a check on the accuracy of the asymptotic expansion method in
\cref{sec:AsymptoticExpansion} for the S-wave and P-wave. The D-wave short-range
integrals cannot be evaluated using the recursion relations in
Ref.~\cite{Pachucki2004} due to the $r_i^{-2}$ terms that appear. Solving these
using the recursion relations would require implementing the extended method in
Ref.~\cite{Pachucki2005}. However, the asymptotic expansion method has proven
to be stable and accurate so far.


\subsubsection{W Functions}
\label{sec:WFunctions}

While evaluating the integrals in the PsH short-range code, we noticed that the
$W$ functions in \cref{eq:FourBodyExpansion} could be called more than once by
multiple integrals. For the S-wave, there are 34 terms in \cref{eq:GradGradShort},
and each matrix element in \textbf{H} in \cref{eq:BoundGenEig} requires these 34
integrals to be evaluated. The overall powers of $r_1$, $r_2$, $r_{12}$, etc.\ in
\cref{eq:FourBody} can be the same for a set of $\phi_i$ with $\phi_j$. Also for a
set of integrals without the overall powers the same, there is the possibility of
two different integrals calling the same $W$ function.

To speed up the program significantly, we precompute the $W$ functions and store
the results in a look up table. The 4-dimensional matrix is constructed with the
limits derived in \cref{chp:WLimits}. Even though there is a possibility for the
$W$ function arguments to be anywhere in this space, not all of the $W$ matrix
elements will be used.

The current S-wave, P-wave and D-wave short-range codes first do a dummy run
where the integrals are not actually calculated, but any $W$ matrix elements
that need to be computed are marked. Only these are computed, and then the code
runs through again using this $W$ matrix look up table. \Cref{tab:WFuncUnusedS}
shows that only $10.6\%$ of the $W$ matrix elements are actually needed for the
S-wave at a relatively high value of $\omega$. Similarly for the D-wave,
\cref{tab:WFuncUnusedD} shows that only $10.5\%$ are needed.

\begin{table}
\centering
\begin{tabular}{c c c c}
\toprule
$\omega$ & Used Terms & Total Terms & Percentage Used \\
\midrule
1 & 	115   &  20,000 & 	0.575\% \\
2 & 	921   &  27,040 & 	3.41\% \\
3 & 	1,939 &  34,992 & 	5.54\% \\
4 & 	3,140 &  43,904 & 	7.15\% \\
5 & 	4,573 &  53,824 &	8.49\% \\
6 & 	6,246 &  64,800 &	9.64\% \\
7 & 	8,147 &  76,880 &	10.6\% \\
\bottomrule
\end{tabular}
\caption{S-wave W function terms used}
\label{tab:WFuncUnusedS}
\end{table}

\begin{table}
\centering
\begin{tabular}{c c c c}
\toprule
$\omega$ & Used Terms & Total Terms & Percentage Used \\
\midrule
0 & 150		&	196,290 &	0.0764\% \\
1 & 1,670	&	259,932 &	0.642\% \\
2 & 14,076	&	332,262 &	4.24\% \\
3 & 23,384	&	413,520 &	5.65\% \\
4 & 36,418	&	503,946 &	7.23\% \\
5 & 51,420  &	603,780 &	8.52\% \\
6 & 68,438	&	713,262 &	9.60\% \\
7 & 87,520	&	832,632 &  10.5\% \\
\bottomrule
\end{tabular}
\caption{D-wave W function terms used}
\label{tab:WFuncUnusedD}
\end{table}

Another more sophisticated method that we have started using is given in
\cref{sec:PrimeFactor}. This looks instead at the overall integrations,
not the $W$ function arguments.



\subsection{Linear Dependence in the Bound State Calculation}
With infinite precision in calculations, all terms from the basis set could be used. However, due to the limited precision inherent in computer calculations, when using large basis sets, near linear dependences will exist in the matrices. The goal is to identify and eliminate terms that exhibit near linear dependence with other terms. These terms are not exactly linearly dependent, if infinite precision was possible, but they are linearly dependent to computer precision.

To calculate the eigenvalues of the generalized eigenproblem, the LAPACK 
routine \texttt{dsygv} is used \cite{dsygv}. For the basis set consisting of 
terms from $\omega$ = 5, LAPACK computes the eigenvalues without errors. 
Adding in terms corresponding to $\omega = 6$ for some sets of nonlinear 
parameters causes \texttt{dsygv} to fail with an error set in the last 
parameter, Info. This error is always an integer greater than the number of 
terms, indicating from the library documentation that ``the leading minor of 
order i of B is not positive definite'' \cite{dsygv}. L\"uchow and 
Kleindienst also encountered a similar problem using NAG and EISPACK
\cite{Luchow1993}.

This error does suggest that one approach to identifying problematic terms is 
to check for positive definiteness of the overlap matrix
$\left\langle \phi_i | \phi_j \right\rangle$. This is one method that
Yan et. al use to isolate 
problematic terms \cite{Yan1999}. They test the eigenvalues of the overlap 
matrix to see if any are small or negative, though there is no mention in 
their paper of what value of ``small'' is used. We attempted to use this fact 
to remove problematic terms, but too many terms were removed, leading to an 
energy that converged too slowly. In several papers by Yan and others
\cite{Yan1998,Yan1998a,Yan1999,Drake1995,Yan1997a}, terms with $j1 > j2$ are 
omitted if $l_1 = l_2$ and $\alpha \approx \beta$, along with $j_1 = j_2$ if
$j_{23} > j_{31}$. These terms were likely determined by trial and error 
or by noticing patterns in terms that produced near linear dependence.

Another technique Yan et al.\ used was to partition the basis set into five 
sectors, each with a different set of nonlinear parameters and maximum
$\omega$ \cite{Yan1999}. The sectors also have restrictions on the interparticle
$r_{ij}$ terms, mainly limiting the power of $r_{23}$ and $r_{31}$, which are the 
electron-positron coordinates in their paper (corresponding to $r_{12}$ and
$r_{13}$ in our work). The techniques used by Yan, Drake and Ho for restricting 
the set of terms are not used in our work.


\subsection{Todd's Method}
\label{sec:ToddBound}

In trying to determine the energy eigenvalues, we noticed that the ordering 
of the terms could determine whether there was linear dependence in the 
matrices. Todd's algorithm \cite{Todd2007,Armour2008} was attractive,
because it reorders the matrices to obtain the best possible energy, and it 
is a purely computational approach. This is very similar to the algorithm
in \cref{sec:LuchowBound} that we also considered. So far, we have not seen 
any physical reason why certain terms should introduce a near linear 
dependence. A description of his algorithm as implemented by us follows.

The total number of terms to look at is $N = N(\omega)$ (see \cref{eq:NumberTermsOmega}).
N matrices of size 1x1 are created for each term. This 
is done for the overlap and the
$\left\langle \phi_i \left| \,H \right| \phi_j \right\rangle$
matrices together. The LAPACK \texttt{dsygv} routine is used to 
determine the lowest eigenvalue for each of these N sets. These energy 
eigenvalues are compared against one another, and the term with the lowest 
energy is chosen. In the next step, the first basis function from the 
previous step is combined with each unused term to create N-1 matrices of 
size 2x2. Again, the energy eigenvalues for each of the N-1 matrices are 
compared against each other, and the term yielding the lowest energy is 
chosen as the second basis function. This is done again with 3x3 matrices for 
each of the N-2 remaining terms combined with the basis functions chosen in 
the first two steps. This procedure is repeated until all terms have been 
used or the remaining terms are problematic.

In his original algorithm, Todd looked at the eigenvalues computed from 
the upper and lower triangular matrices. Normally, the overlap and H matrices 
are symmetric, but this is not true to machine precision due to truncation 
and rounding. If the energy eigenvalues from the upper and lower triangles 
differ by more than $10^{-6}$ (in atomic units), the last added term is 
considered problematic and discarded.

In our testing for $\omega = 6$ for the S-wave, no terms were omitted due to the reordering. 
As noted earlier, before implementing this algorithm, LAPACK would fail when 
trying to calculate the eigenvalues, so the ordering is important for getting 
the best possible energy. For $\omega$ = 7, 116 terms were omitted, out of a 
total of 1716 terms. The criteria that the eigenvalues for the upper and 
lower matrices differs by no more than a certain amount was not needed in 
this case. The Info parameter of the LAPACK dsygv function is checked for 
both the upper and lower matrix eigenvalue calculations, and the last added 
term is discarded if it causes an error due to linear dependence. When only 
the 116 problematic terms were left, every one of them caused LAPACK to 
error. If a term was problematic at any stage, it continued to be problematic 
in all further stages, so computation time can be decreased by immediately 
discarding it.

For larger basis sets, this algorithm becomes extremely slow, as determining 
the eigenvalues is an $O(N^3)$ operation. It can easily be parallelized, 
since we are computing the eigenvalues for a large number of matrices. Our 
program has been parallelized using OpenMP \cite{OpenMP} for intranode
communications and MPI \cite{MPI} for internode communications. Todd's
algorithm provides the best converged energy for a set of terms, albeit
at a cost of computational speed.

\begin{figure}
	\centering
	{\includegraphics[height=1.5in]{Todd}}
	\caption{Diagram of Todd's procedure}
	\label{fig:Todd}
\end{figure}



\subsection{Restricted Set}
\label{sec:Restricted}
Van Reeth and Humberston \cite{VanReeth2003} found that restricting the power 
of the $r_3$ coordinate could significantly improve their numerics, allowing 
them to use more short-range terms. Specifically, we restrict the $r_3$ power 
(see \cref{eq:PhiDef}) so that $n_i \leq 2$ if $\omega \geq 3$, and we refer 
to this as the restricted set.

We normally use Todd's method applied to the scattering problem,
described in \cref{sec:CompPhase}, or we 
use the full unrestricted set when possible. For the cases of $^1$F and $^3$F 
for low $\kappa$, described in \cref{sec:FNonlinear}, we use the restricted 
set. This allowed us to keep the convergence ratios less than 1 for these
cases.


\section{Long-Range Terms}
\label{sec:CompLong}

To minimize verbosity, the long-long and long-short integrations are 
collectively referred to as the long-range integrations. Each of the
long-range integrations are performed using Gaussian quadratures, which
are described fully in \cref{sec:GaussQuad}. 


\subsection{Long-Range -- Long-Range}
\label{sec:LongLongInt}

The scattering program calculates only the short-long and long-long matrix 
elements. The volume element in \cref{eq:dTauS23} has an internal angle 
of $\varphi_{23}$ to integrate over.  When a term has a a negative power of
$r_{23}$, a large number of integration points must be used for reasonable 
accuracy. Instead, we split the integration such that one part is missing 
the $r_{23}^{-1}$ term and the other contains only the $r_{23}^{-1}$ term.

The first integration excluding the $r_{23}^{-1}$ term has negative powers of 
$r_i$ and $r_{ij}$ canceled by the corresponding terms in the volume element 
given by \cref{eq:dTauS23}. For the integration over the $r_{23}^{-1}$ term, 
we use an alternative volume element, namely that given by equation
\cref{eq:dTauS12}.
The $r_{23}^{-1}$ is then canceled by the $r_{23}$ in this volume element.


\subsubsection{Integration without the \texorpdfstring{$r_{23}^{-1}$} {1/r23} term}
\label{sec:LongLongNoR23}
The simplest long-long matrix element to evaluate is
$(\bar{S}_\ell,\mathcal{L} \bar{S}_\ell)$. From \cref{eq:SbarLSbar}, not
including its $r_{23}^{-1}$ term, this is
\beq
(\bar{S}_\ell,\mathcal{L} \bar{S}_\ell)_A = \pm \left(S_\ell^\prime,\mathcal{L} S_\ell\right)_A = \pm \left(S_\ell^\prime, \left[ \frac{2}{r_1} - \frac{2}{r_2} - \frac{2}{r_{13}}\right] S_\ell\right).
\eeq

For this type of integration, we use perimetric coordinates as described in
\cref{sec:PerimetricCoords}.
\begin{align}
\label{eq:SBarSBarInt}
(\bar{S}_\ell,\mathcal{L} \bar{S}_\ell)_A = \pm &2\pi^2 \int_0^\infty \int_0^\infty \int_0^\infty \int_0^\infty \int_{|r_1 - r_3|}^{|r_1 + r_3|} \int_0^{2\pi}  S_\ell^\prime S_\ell \left[ \frac{2}{r_1} - \frac{2}{r_2} - \frac{2}{r_{13}}\right] \\
&\times r_2 r_3 r_{12} r_{13}\, d\varphi_{23}\, dr_{13}\, dr_3\, dz\, dy\, dx
\end{align}

The $\varphi_{23}$ integration is done analytically. Since $S_\ell$ and
$S_\ell^\prime$ have no $r_{23}$ dependence and there is no $r_{23}$ term in
the brackets, the integration over $\varphi_{23}$ is simply $2\pi$. The
$r_{13}$ integration uses the Gauss-Laguerre quadrature from
\cref{sec:GaussLegendre}. The $x$, $y$ and $z$ integrations use Gauss-Laguerre 
quadrature, since they are semi-infinite.

The $r_3$ integration could also be performed using just the Gauss-Laguerre 
quadrature. However, the integrand for the $r_3$ integration has a 
discontinuity in its slope at $r_3=r_1$, creating a cusp
(see \cref{sec:Cusps}), so the accuracy is improved greatly if we split the
integration interval into two parts and employ different quadratures for each.
The integration is split to use Gauss-Legendre on the interval $(0,r_1)$ and
Gauss-Laguerre on the interval $(r_1,\infty)$.

\subsubsection{Integration over the \texorpdfstring{$r_{23}^{-1}$} {1/r23} term}
%\subsection[Integration over the 1/r23 term]{Integration over the $r_{23}^{-1}$ term}
\label{sec:LongLongR23}
The other part of the $(\bar{S}_\ell,\mathcal{L} \bar{S}_\ell)$ integral
contains the $r_{23}^{-1}$ term.

\beq
(\bar{S}_\ell,\mathcal{L} \bar{S}_\ell)_B = \pm \left(S_\ell^\prime, \left[ \frac{2}{r_{23}}\right] S_\ell\right)
\eeq
%\todoi{Why exactly do we use perimetric coordinates?}
The volume element for this integral is $d\tau$ from \cref{eq:dTauS12}.
The integration also does not need to be converted to perimetric coordinates,
so its form is
\begin{align}
(\bar{S}_\ell,\mathcal{L} \bar{S}_\ell)_B = \pm 8\pi^2 \int_0^\infty & \int_0^\infty \int_0^\infty \int_{|r_1 - r_3|}^{|r_1 + r_3|} \int_{|r_2 - r_3|}^{|r_2 + r_3|} \int_0^{2\pi}  S_\ell^\prime S_\ell \frac{2}{r_{23}} r_1 r_2 r_{13} r_{23} \nonumber \\
& \times d\varphi_{12}\, dr_{23}\, dr_{13}\, dr_2\, dr_3\, dr_1.
\end{align}
%\todoi{Check that we do this over $\varphi_{12}$.}

The $r_{13}$ and $r_{23}$ integrals have finite limits, so here we use Gauss-
Legendre quadrature. Again, for the internal angular integration, this time 
over $\varphi_{12}$, we use Chebyshev-Gauss quadrature. The cusp in the $r_3$ 
integration is at $r_3 = r_1$, and the cusp in the $r_2$ integration is at
$r_2 = r_3$. Similar to before, we split up these integrations by using Gauss-
Legendre before the cusp and Gauss-Laguerre after the cusp.

The $(\bar{C}_\ell,\mathcal{L} \bar{S}_\ell)$ and
$(\bar{C}_\ell,\mathcal{L} \bar{C}_\ell)$ terms
are integrated in the same manner as the
$(\bar{S}_\ell,\mathcal{L} \bar{S}_\ell)$ integral just described. With all
four matrix elements calculated, as mentioned on \pageref{GenSLCandCLS}, if
the difference of $(\bar{S}_\ell,\mathcal{L} \bar{C}_\ell)$ and
$(\bar{C}_\ell,\mathcal{L} \bar{S}_\ell)$ is close to 1, we can have reasonable
confidence in the long-long integrations. Another check is that if we
explicitly calculate $(S_\ell,\mathcal{L} S_\ell)$, we should get 0
(\cref{eq:SLS0Test}). We find that the choice of innermost integration,
over $\varphi_{12}$ or $\varphi_{13}$, can cause this to be nonzero, so this
gives us another check on the accuracy of the long-long integrations.


\subsection{Short-Range -- Long-Range}
\label{sec:ShortLongInt}
We will consider only the $(\bar{\phi}_i,\mathcal{L} \bar{S}_\ell)$ 
integrations here, as the $(\bar{\phi}_i,\mathcal{L} \bar{C}_\ell)$ integrals 
are evaluated in the same manner. As in the case of long-range -- long-range 
integrations in \cref{sec:LongLongInt}, we split up the integration 
into two parts -- one containing the $r_{23}^{-1}$ term and another 
containing the rest of the terms. The short-range terms have the added 
benefit of the possibility of the polynomial $r_{23}^{\,q_i}$ being present, 
which cancels the $r_{23}^{-1}$ term or gives it an overall positive power.


From \cref{eq:PhiBarLSBar2b,eq:LSFinal,eq:LSPrimeFinal},
\begin{align}
\label{eq:PhiLSBarInt}
\nonumber (\bar{\phi}_i, \mathcal{L} \bar{S}_\ell) &= \frac{2}{\sqrt{2}} \left(\phi_i,\mathcal{L} \bar{S}_\ell\right) \\
 &= \frac{2}{\sqrt{2}} \int \phi_i \left[ \left( \frac{2}{r_1} - \frac{2}{r_2} - \frac{2}{r_{13}} + \frac{2}{r_{23}} \right)S_\ell \pm \left( \frac{2}{r_1} - \frac{2}{r_3} - \frac{2}{r_{12}} + \frac{2}{r_{23}} \right) S_\ell^\prime \right]  d\tau.
\end{align}

\subsubsection{Case I: \texorpdfstring{$q_i > 0$}{qi > 0}}
\label{sec:Swaveqigt0}
When $q_i > 0$ in $\phi_i$ (\cref{eq:PhiDef}), the power of $r_{23}$ is
equal to or greater than 0. Gaussian quadratures can safely integrate this type
of term, so we integrate the full expression in \cref{eq:PhiLSBarInt}.
\begin{align}
\label{eq:PhiLSBarIntFull}
\nonumber (\bar{\phi}_i, \mathcal{L} \bar{S}_\ell) =& \, \frac{2}{\sqrt{2}} \cdot 8\pi^2  \int_0^\infty \int_0^\infty \int_0^\infty \int_{|r_1 - r_2|}^{|r_1 + r_2|} \int_{|r_1 - r_3|}^{|r_1 + r_3|} \int_0^{2\pi} \phi_i \\
&\times \left[ \left( \frac{2}{r_1} - \frac{2}{r_2} - \frac{2}{r_{13}} + \frac{2}{r_{23}} \right)S_\ell \pm \left( \frac{2}{r_1} - \frac{2}{r_3} - \frac{2}{r_{12}} + \frac{2}{r_{23}} \right) S_\ell^\prime \right] \\
&\times r_2 r_3 r_{12} r_{13}\, d\varphi_{23}\, dr_{13}\, dr_{12}\, dr_3\, dr_2\, dr_1
\end{align}

Similar to the long-long integrations from \cref{sec:LongLongInt}, the 
$r_1$ integration is performed using the Gauss-Laguerre quadrature. The $r_2$
integral is broken into two parts at the cusp of $r_2 = r_1$, with the
Gauss-Legendre quadrature before the cusp and the Gauss-Laguerre quadrature 
after the cusp. In the $r_3$ coordinate, there is a cusp at $r_3 = r_2$, so 
the integration is also split up into Gauss-Legendre before the cusp and
Gauss-Laguerre after the cusp. The finite intervals for $r_{12}$ and $r_{13}$ 
ensure that we can use Gauss-Legendre quadratures for these coordinates. The 
$\varphi_{23}$ integration uses the Chebyshev-Gauss quadrature.

\subsubsection{Case II: \texorpdfstring{$q_i = 0$}{qi = 0}}
When $q_i = 0$, the overall power of the $r_{23}$ term is $-1$, so we 
cannot use the Gaussian quadratures in the form of \cref{eq:PhiLSBarIntFull}.  
Similar to the long-long integrations, the $r_{23}^{-1}$ term is integrated 
separately, using the same type of integrations as \cref{eq:PhiLSBarIntFull}.
Refer to the previous section for the description of the quadratures used.
\begin{align}
\label{eq:PhiLSBarIntNoR23}
\nonumber (\bar{\phi}_i, \mathcal{L} \bar{S}_\ell)_A =& \,\frac{2}{\sqrt{2}} \bigintsss \phi_i \left[ \left( \frac{2}{r_1} - \frac{2}{r_2} - \frac{2}{r_{13}} \right)S_\ell \pm \left( \frac{2}{r_1} - \frac{2}{r_3} - \frac{2}{r_{12}} \right) S_\ell^\prime \right]  d\tau \\
\nonumber =&\, \frac{2}{\sqrt{2}} \cdot 8\pi^2  \int_0^\infty \int_0^\infty \int_0^\infty \int_{|r_1 - r_2|}^{|r_1 + r_2|} \int_{|r_1 - r_3|}^{|r_1 + r_3|} \int_0^{2\pi} \phi_i r_2 r_3 r_{12} r_{13} \\
&\times \left[ \left( \frac{2}{r_1} - \frac{2}{r_2} - \frac{2}{r_{13}} \right)S_\ell \pm \left( \frac{2}{r_1} - \frac{2}{r_3} - \frac{2}{r_{12}} \right) S_\ell^\prime \right]  d\varphi_{23}\, dr_{13}\, dr_{12}\, dr_3\, dr_2\, dr_1
\end{align}

The integration over the $r_{23}^{-1}$ term is done the same way as the 
second integration of the long-long matrix elements in \cref{sec:LongLongInt}.
The $r_{23}$ in the $d\tau$ volume element cancels the $r_{23}^{-1}$ 
term. Refer to \cref{sec:LongLongR23} for a description of 
the quadratures used here.
\begin{align}
\label{eq:PhiLSBarIntR23}
(\bar{\phi}_i, \mathcal{L} \bar{S}_\ell)_B =& \,\frac{2}{\sqrt{2}} \bigintsss \phi_i \left[ \frac{2}{r_{23}}\left(S_\ell \pm S_\ell^\prime\right) \right] d\tau^\prime  \nonumber \\
=&\, \frac{2}{\sqrt{2}} \cdot 8\pi^2  \int_0^\infty \int_0^\infty \int_0^\infty \int_{|r_1 - r_3|}^{|r_1 + r_3|} \int_{|r_2 - r_3|}^{|r_2 + r_3|} \int_0^{2\pi} \phi_i \left[ \frac{2}{r_{23}}\left(S_\ell \pm S_\ell^\prime\right) \right]  \nonumber \\
&\times  r_1 r_2 r_{13} r_{23}\, d\varphi_{12}\, dr_{23}\, dr_{13}\, dr_2\, dr_3\, dr_1
\end{align}

%\todoi{Check that we do this over $\varphi_{12}$.}

For a discussion on the final quadrature points used, refer to \cref{sec:QuadraturePoints}.




\subsection{Cusp Behavior}
\label{sec:Cusps}

The short-long and long-long matrix element integrals have cusps in the
integrands that must be dealt with. As an example, consider
$(\bar{\phi}_i, L\bar{C}_0)$ from the S-wave. Using the notation of
\cref{sec:LongLongR23}, where we are only computing the $r_{23}^{-1}$ terms
(given fully later in \cref{eq:LCBar} on \pageref{eq:LCBar}),
\begin{align}
(\bar{\phi}_i, L\bar{C}_0)_B = 8\pi^2 & \int_0^\infty \int_0^\infty \int_0^\infty \int_{|r_1 - r_2|}^{|r_1 + r_2|} \int_{|r_2 - r_3|}^{|r_2 + r_3|} \int_0^{2\pi} \bar{\phi}_i (\mathcal{L} \bar{C})_B  \nonumber \\
& \times r_1 r_3 r_{13} r_{23}\, d\varphi_{13}\, dr_{23}\, dr_{12}\, dr_3\, dr_2\, dr_1.
\end{align}
Due to the integration limits of the $r_{13}$ and $r_{23}$ integrations, the
$r_2$ integrand has a cusp at $r_2 = r_1$, and the $r_3$ integrand has a cusp
at $r_3 = r_2$.

\Cref{fig:cusp} shows one such example of this cusp behavior for the $r_2$ 
integrand. All inner integrations ($\varphi_{13}$, $r_{23}$, $r_{12}$, and $r_3$)
are performed with a full set of integration points as described in
\cref{tab:OptimalEffectiveCoords}.

\begin{figure}
	\centering
	\includegraphics[width=5in]{cusp}
	\caption[Example of cusp in S-wave short-long integration]{Example of cusp
in S-wave short-long integration for $1/r_{23}$ term of
$(\bar{\phi}_3, \mathcal{L}\bar{C}_0)$ with \mbox{$r_1 = 18.201$}}
	\label{fig:cusp}
\end{figure}

The $r_2$ integration could be performed using just the Gauss-Laguerre 
quadrature, since we are integrating over $[0,\infty)$. However, the cusp 
makes this integration slowly convergent. We instead split the integration 
interval into two parts and employ different quadratures for each. The 
integration is split to use Gauss-Legendre (\cref{eq:GaussLegGen}) on the 
interval $[0,r_1]$ and Gauss-Laguerre (\cref{eq:GaussLagGen}) on the interval 
$[r_1,\infty)$. Likewise, the $r_3$ integration is split into the intervals
$[0,r_2]$ and $[r_2,\infty)$.

Doing this splitting requires many more function evaluations, so we use an 
approximation whenever $r_1$ is large enough. Specifically when $r_1$ is 
greater than a chosen distance, we use Gauss-Laguerre over the entire
$[0,\infty)$ range. 
In the example given in \cref{fig:cusp}, at $r_2 = 100$, the $r_2$ integrand 
is approximately $10^{-57}$, while at $r_2 = 25$, the integrand is 
approximately $10^{-9}$.


For the S-wave, all runs were performed with the cusp parameters set at
$r_1 = 100$. When $r_1 > 100$, the $r_2$ and $r_3$ integrations are done using only 
Gauss-Laguerre, since the cusp is considered unimportant at that distance. 
When $r_1 \leq 100$, we use Gauss-Legendre before the cusp and Gauss-Laguerre 
after the cusp, as described in \cref{sec:LongLongNoR23,sec:LongLongR23}. 

Van Reeth and Humberston used cusp parameters set at $r_1 = 25$, with little 
apparent loss of precision over using $r_1 = 100$ \cite{VanReethPrivate}. 
With $\kappa$ set at $0.1$, several tests were performed with different cusp 
parameters. With cusp parameters of 100, for $\omega = 6$, we are able to use 
910 terms, giving a phase shift of $-0.427$. Doing the same run with cusp 
parameters of 25 allows us to use the same number of terms and gives a phase 
shift of $-0.427$ as well. In this particular example, the two sets of cusp 
parameters (25 and 100) differ in the sixth decimal place. As an example, for 
the inverse Kohn, $\delta = -0.42707291$ for the cusp parameters of 100, 
while $\delta = -0.42707370$ for cusp parameters of 25. To the required 
accuracy, the cusp parameters of 25 are sufficient for this example.

Smaller values for these cusp parameters were also tried, and these tests are 
summarized in \cref{tab:SWaveCuspParameters}. When the cusp parameters 
are too small, such as the cases of 5, 10 and 15, the phase shifts do not 
converge well and start to diverge much earlier. The second column in this 
table shows the number of terms we can use for each set, but the number of 
terms to use is not exact due to the lack of good convergence, so the values 
here are approximate for small cusp parameters. The phase shift given for 
these three tests are therefore approximate as well. From this table, we 
conclude that 20 is the minimum value needed, at least for the $\kappa = 0.1$ 
case tested here for the $S$-wave. To be conservative, runs use cusp 
parameters of 100. 



\begin{table}
\centering
\begin{tabular}{c c c}
\toprule
Cusp parameter & Terms possible & $\delta_0^+$ \\
\midrule
 5 & 531 & -0.4281 \\
10 & 684 & -0.4071 \\
15 & 684 & -0.4267 \\
20 & 910 & -0.4271 \\
25 & 910 & -0.4271 \\
100 & 910 & -0.4271 \\
\bottomrule
\end{tabular}
\caption{S-wave cusp parameters for $\kappa = 0.1$ at $\omega = 6$}
\label{tab:SWaveCuspParameters}
\end{table}

\begin{table}
\centering
\begin{tabular}{c c}
\toprule
Cusp parameter & $\delta_1^+$ \\
\midrule
 25 & 1.142923114 \\
 50 & 1.142923115 \\
100 & 1.142924602 \\
\bottomrule
\end{tabular}
\caption{P-wave cusp parameters for $S$ matrix $\kappa = 0.7$ at $\omega = 5$}
\label{tab:PWaveCuspParameters}
\end{table}


\begin{table}
\centering
\begin{tabular}{c c c}
\toprule
Cusp parameter & $\delta_2^+$ & Time (hours) \\
\midrule
100 & 0.173 924 955 404 676 & 7.8 \\
150 & 0.173 924 955 404 797 & 8.9 \\
200 & 0.173 924 955 404 809 & 10.2 \\
250 & 0.173 924 955 404 748 & 10.8 \\
\bottomrule
\end{tabular}
\caption{D-wave cusp parameters for $S$ matrix $\kappa = 0.6$ at $\omega = 3$}
\label{tab:DWaveCuspParameters}
\end{table}


\subsection{Extra Exponential}
\label{sec:ExtraExp}
To further improve the convergence of the short-long matrix elements in 
equation \cref{eq:GeneralKohnMatrix}, we investigated the integrands.
The biggest source of 
difficulty in converging these results comes through the Gauss-Laguerre 
quadratures in the $r_1$, $r_2$ and $r_3$ integrations. Specifically, the 
region near the origin is not adequately represented. The integrands fall off 
quickly due to the exponential falloffs in $r_1$, $r_2$ and $r_3$, so it is 
not as important to have abscissae far away from the origin.
We are using approximately 7 times as many integration points total as the
earlier Kohn and inverse Kohn work \cite{VanReeth2003,VanReeth2004}
(see \cref{sec:QuadraturePoints}), but this brute force approach of adding 
quadrature points can increase the computational time greatly. We took 
another approach to further increase the accuracy. For each of the Gauss-
Laguerre quadratures, we introduce an extra $e^{-\lambda r_i}$ and remove it 
with $e^{\lambda r_i}$ after the quadrature, bringing the abscissae closer to 
the origin without increasing the number of integration points.

The basic form of the Gauss-Laguerre quadrature is given in \cref{eq:GaussLag} as
\beq
\int_0^\infty e^{-x} f(x) dx \approx \sum_{i=1}^n w_i f(x_i).
\eeq
Introducing an extra $e^{-\lambda x}$ and removing it with $e^{\lambda x}$, we can bring the abscissae closer in by
\beq
\label{eq:GaussLagLambda}
\int_0^\infty e^{-x} f(x) dx \approx \sum_{i=1}^n \frac{w_i}{\lambda} f\! \left(\frac{x_i}{\lambda}\right) \ee^{\lambda x_i}.
\eeq

As an example, the full expression for the $r_2$ Gauss-Laguerre quadrature is given by
\beq
\int_a^\infty e^{-\beta r_2} f(r_2) dr_2 \approx \frac{e^{-\beta a}}{\beta} \sum_{i=1}^n w_i f\left(\frac{y_i}{\beta}+a\right),
\eeq
where $y_i = \beta x_i$. With the exponential in $\lambda$, this becomes
\beq
\int_a^\infty e^{-\beta r_2} f(r_2) dr_2 \approx \frac{e^{-a (\beta + \lambda)}}{\beta + \lambda} \sum_{i=1}^n w_i f\left(\frac{r_2 + a(\beta + \lambda)}{\beta + \lambda} \right) \ee^{\lambda r_2}.
\eeq

\begin{figure}
	\centering
	\includegraphics[width=5in]{lambda}
	\caption{Effect of introducing $\lambda$ in $r_1$ exponential}
	\label{fig:lambda}
\end{figure}

\Cref{fig:lambda} shows the effect of introducing this $\lambda$ into the $r_1$
exponential. We use 50 quadrature points for each curve, meaning that there 
are points represented past the cutoff of 18 au in the graph. For the black 
curve with $\lambda = 0$, the curve is very jagged around the peak of 
approximately 4 au. With $\lambda = 1.0$, the curve is much smoother, and as
$\lambda$ is increased to 2.0, the peak is represented even better. If $\lambda$
is too large, the area near the origin may be overrepresented and the area 
farther out may be underrepresented. We have chosen $\lambda = 1.0$ for all 
of our runs for the $r_1$, $r_2$ and $r_3$ coordinates, which gives better
representation near the origin but does not  run the risk of neglecting the
small contribution of the curve for large $r_i$ values. Our $D$-wave and
general long-range codes could use different $\lambda$ for each of the
$r_1$, $r_2$ and $r_3$ integrations, but we set them equal here. The matrix
elements converge better for $\lambda = 1.0$ than for $\lambda = 0$.
%\todoi{Can we quantify this?}


\section{Phase Shifts}
\label{sec:CompPhase}

We solve for the phase shifts by solving \cref{eq:GeneralKohnMatrix} for
$\boldsymbol{X}$ and then using \cref{eq:GenDFDT2,eq:GenKohnL}. Note that
as mentioned in \cref{sec:Kohn}, we only have to calculate one set of integrals
for the Kohn variational method, and the other Kohn methods are
used by rearrangement of these integrals in the matrix equation. The different
Kohn-type variational methods typically agree well when linear dependence in the
matrix equation does not occur. We use this fact to determine how many
short-range terms we are able to use in our final calculations. If we plot the
phase shifts with respect to the number of terms, as in \cref{fig:swave-phase-divergence},
it is clear that around 1530 terms, the phase shifts from the different
generalized Kohn methods begin to diverge. In this particular example, we
chose the cutoff as a more conservative 1505 terms--before the ``jump'' that 
precedes the clear divergence. No Schwartz singularities (\cref{eq:SchwartzSing})
are evident here, but if any are present, we discard the Kohn methods that
contain spurious singularities.

\begin{figure}
	\centering
	\includegraphics[width=5in]{swave-phase-divergence}
	\caption{Breakdown in convergence of the $^1S$ phase
shifts with respect to number of short-range terms for different $\tau$
values for the generalized Kohn variational method}
	\label{fig:swave-phase-divergence}
\end{figure}

Using the short-range terms chosen by the Todd method (\cref{sec:ToddBound})
normally allows us to increase the number of terms used over using the terms
chosen just by \cref{eq:OmegaDef} for the Ps-H scattering problem.
Since the Todd method chooses an ordering with the most ``important'' terms 
at the beginning, we obtain well-converged phase shifts using this method with
the above-mentioned cutoffs for the first two partial waves (which do not 
have omitted symmetries). So we perform one truncation of the basis set by
using the Todd method for just the short-range terms and then an additional 
truncation by using plots as in \cref{fig:swave-phase-divergence} to reduce
linear dependence.

The number of terms used for each partial wave are given in \cref{sec:NonlinParam},
denoted as $N'(\omega)$. For $\ell \geq 3$, we either use the full set of
terms described by \cref{eq:OmegaDef} or the restricted set described in
\cref{sec:Restricted}.

The phase shifts presented in this work are found using the $S$-matrix 
complex Kohn, unless otherwise indicated. We normally only use the Kohn, 
inverse Kohn, and generalized Kohn variational method results to determine 
the number of short-range terms to use as described in this section. Then the 
phase shifts for this set of terms with the $S$-matrix complex Kohn method 
are determined.

%\todoi{Mention $\mu$ variation for S-wave}



%%\subsection{Phase Shift Convergence and Singularities}
%%Schwartz singularities are well-documented \cite{Lucchese1989,Cooper2009} and 
%%are non-physical ``resonances''. To avoid these singularities, we use 
%%multiple forms of the Kohn method: Kohn, inverse Kohn, generalized Kohn, 
%%generalized S-matrix complex Kohn, and generalized T-matrix complex Kohn. 
%%There may also be spurious results if the matrix elements are not converged, 
%%with one example being the feature at approximately 600 terms in
%%\cref{fig:OriginalPhaseShifts-pvr} for the inverse Kohn. With the original
%%ordering of the short-range terms, the phase shifts always break up at around
%%1100 terms, even when the matrix elements are converged. To alleviate this 
%%problem, we have implemented the Todd algorithm.
%%
%%\subsection{Todd Algorithm Applied to the Scattering Problem}
%%\label{sec:ToddScattering}
%%\todoi{Reword for other than just $S$}
%%From the bound state calculation using Todd's algorithm mentioned in
%%\cref{sec:ToddBound}, we know which short-range Hylleraas terms approximate 
%%the wavefunction of PsH best. We have observed that the short-short
%%terms used in the same order as the output of the Todd algorithm will 
%%generate well-converged phase shifts. The separate code to determine the 
%%phase shifts uses the output from the bound state code. Again, the phase 
%%shift is plotted with respect to the number of short-range terms. The result 
%%is in \cref{fig:ToddPhaseShifts-pvrplus5}. The phase shifts are 
%%converged well until term 1216. A magnification of the graph in the small 
%%region around this term is provided in the inset graph.
%%
%%At term 1216, the Kohn method result starts to diverge from the others. 
%%Shortly after term 1280, the five different methods for $\tau = 0.0 - 0.5$ 
%%start to diverge slightly. The differences here are very small (on the order 
%%of $10^{-5}$), unlike in \cref{fig:OriginalPhaseShifts-pvrplus5}. The 
%%jump in phase shifts seen in \cref{fig:OriginalPhaseShifts-pvrplus5} 
%%does not take place until much later and is not as large. Near 1650 terms, 
%%the phase shifts are not well converged, but they are also not as nearly
%%ill-behaved as the results in \cref{fig:OriginalPhaseShifts-pvrplus5}.
%%
%%\begin{figure}
	%%\centering
	%%\includegraphics[width=\textwidth]{ToddPhaseShifts-pvrplus5}
	%%\caption{Phase shifts with Todd terms and 5 extra points}
	%%\label{fig:ToddPhaseShifts-pvrplus5}
%%\end{figure}
%%
%%
%%\subsection{Todd Algorithm with Optimized Quadrature}
%%
%%
%%\begin{figure}
	%%\centering
	%%\includegraphics[width=\textwidth]{ToddOrderKohnPhaseShiftsOpt7}
	%%\caption{Phase shifts with Todd ordering and optimal set of points}
	%%\label{fig:ToddOrderKohnPhaseShiftsOpt7}
%%\end{figure}
%%
%%
%%\begin{figure}
	%%\centering
	%%\includegraphics[width=\textwidth]{ToddPhaseShifts-pvrbest}
	%%\caption{Phase shifts with resorted Todd terms and optimal set of points}
	%%\label{fig:ToddPhaseShifts-pvroptimized}
%%\end{figure}
%%
%%Section \ref{sec:QuadraturePoints} has a discussion on the ``optimal set'' of quadrature points. When this optimal set is used with Todd's method, a very stable set of phase shifts is created. The graph in figure \ref{fig:ToddOrderKohnPhaseShiftsOpt7} shows how the phase shifts are well converged up to 1450 terms. At approximately term 1450, the phase shifts for the various Kohn methods begin to diverge. The Kohn results begin to diverge earlier than the other three variants in figure \ref{fig:ToddOrderKohnPhaseShiftsOpt7}. Notice that a similar behavior occurs in figure \ref{fig:ToddPhaseShifts-pvrplus5} at 1216 terms.
%%
%%We have not developed an automated method of determining where this divergence occurs, so a visual inspection of the graph is needed. Graphs like the above are created in gnuplot, but we have developed a MATLAB script that makes this much easier. This script loads and plots data from all variations on the Kohn method, including the 35 values of $\tau$ for the generalized Kohn. MATLAB allows zooming of figures, so it is simple to find the term where the phase shifts begin to diverge.
%%
%%For the extrapolation method discussed in section \ref{sec:Extrapolation}, it is useful to reorder the terms in the original ordering with increasing $\omega$. The first 1450 terms of figure \ref{fig:ToddOrderKohnPhaseShiftsOpt7} are used and then reordered, leading to the graph in figure \ref{fig:ToddPhaseShifts-pvroptimized}. There is a very small difference between the Kohn methods, but they do not diverge as in figure \ref{fig:ToddPhaseShifts-pvroptimized} after 1450 terms.
%%
%%
%%\todoi{Table of number of terms chosen from paper}
%%
%%
%%\subsection{Generalized Kohn}
%%\label{sec:CompGenKohn}
%%
%%\todoi{Move this}
%%
%%As mentioned in \cref{sec:GenKohn}, the generalized Kohn method described by 
%%Cooper et al.\ allows for an adjustable parameter $\tau$ to be used. For our 
%%calculations of the Kohn and inverse Kohn, we set $\tau = 0$ and
%%$\tau = \frac{\pi}{2}$, respectively. Before we started using the generalized 
%%Kohn method, it was difficult to tell if the difference between the Kohn and 
%%inverse Kohn phase shifts was due to a Schwartz singularity or a problem with 
%%linear dependence. With the generalized Kohn, we have a large number of 
%%individual Kohn methods to compare the results with.
%%
%%The phase shift program steps through $\tau = 0$ to $\tau = 3.0$ in 
%%increments of $0.1$ for each N. The code can also be easily modified to use 
%%any value of $\tau$, which was used in \cref{fig:PhaseTau}.
%%
%%The Kohn methods do not require a recalculation of the entire problem for each Kohn method. Once the original matrix equation (\cref{eq:GeneralKohnMatrix}) is calculated with the $\textbf{u}$ in \cref{eq:uKohn}, along with the $(\bar{S},\mathcal{L} \bar{S})$ term, the elements are reused to perform the other Kohn method calculations in \cref{sec:KohnApplied}.
%%
%%
%%
%%\setlength{\abovecaptionskip}{0pt}   % 0.5cm as an example
%%
%%\begin{figure}
	%%\centering
	%%\includegraphics[width=\textwidth]{PhaseTau}
	%%\caption[Phase shifts versus $\tau$ in the generalized Kohn method]{Phase shifts versus $\tau$ in the generalized Kohn method for $^1$S Ps-H scattering $(\omega = 7, \kappa = 0.1)$}
	%%\label{fig:PhaseTau}
%%\end{figure}
%%
%%\todoi{Redo \cref{fig:PhaseTau} in IPython}





\section{Convergence and Extrapolations}
\label{sec:Extrapolations}

For comparing quantities such as the convergence of the matrix elements or 
the convergence of the differential cross sections, we use the percent
difference. There is no standard symbol for this, so we define it as
\begin{equation}
\label{eq:PercentDiff}
%\% \text{ Diff} = \rhd(a,b) = \left| \frac{a - b}{(a + b) / 2} \right| \times 100\%.
\% \text{ Diff} = \left| \frac{a - b}{(a + b) / 2} \right| \times 100\%.
\end{equation}
When we can compare convergence with respect to $\omega$, we define a
convergence ratio as
\begin{equation}
\label{eq:ConvRatio}
R'(\omega) = \frac{\delta_\ell^\pm(\omega)-\delta_\ell^\pm(\omega-1)}
  {\delta_\ell^\pm(\omega-1)-\delta_\ell^\pm(\omega-2)}.
\end{equation}
This is similar to the inverse of the ratio for the energy eigenvalues given in
Ref.~\cite{Yan1999}. If $R'(\omega) \geq 1$, there is no convergence
pattern. A ratio of less than 1 shows convergence but does not guarantee a
reliable extrapolation. We find that $R'(\omega) \lesssim 0.5$ is
needed to properly extrapolate phase shifts. We also find that when
$\delta_\ell \lesssim 10^{-4}$, the convergence often becomes poor
(see \cref{sec:DWavePhase}).

The tangent of the phase shifts is fitted to the function
\beq
\label{eq:PhaseExtrap}
\tan \delta_\ell^\pm(\omega) = \tan \delta_\ell^\pm(\omega \to \infty) + \frac{c}{\omega^p}.
\eeq
The $c$ and $p$ in this equation are fitting parameters. When plotted with respect to $\omega^{-p}$, the tangents of the phase shifts form nearly a straight line, with the y-intercept being the tangent of the extrapolated value of the phase shift, $\tan \delta^\pm(\omega \to \infty)$.

In Van Reeth and Humberston, the extrapolation is done using $\omega = 3$ 
through $\omega = 6$ \cite{VanReeth2003}. The current results go to $\omega = 7$, so 
we have completed the extrapolation using the sets $\omega = 3-6$,
$\omega = 3-7$ and $\omega = 4-7$. The smallest residuals are normally found
with the set $\omega = 4-7$. The values of the extrapolated phase shifts using
this method are in \cref{tab:SWavePhase}.

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{extrap-phase}
	\caption[Extrapolation for $^1$S at $\kappa = 0.01$]{Extrapolation for $^1$S at $\kappa = 0.01$. The extrapolation without resorting the short-range terms into increasing $\omega$ is given in (a), and the resorted version is in (b).}
	\label{fig:extrap-phase}
\end{figure}

As described in \cref{sec:ToddBound}, we omit certain terms using 
Todd's method. The output of this method from the bound state program 
described in \cref{sec:ToddBound} is not ordered in terms of 
increasing $\omega$. This leads to difficulties when attempting to do the 
extrapolation in \cref{eq:PhaseExtrap}. The tangent of the phase 
shifts cannot be fitted to a straight line in this order. If we reorder the 
short-range terms back into their original order while still omitting terms, 
the tangent of the phase shifts can now be fitted to this straight line, as 
can be seen in \cref{fig:extrap-phase}. The reordering does not affect 
the phase shifts in any case that we tested, since more terms are normally 
omitted in the scattering problem than just the bound state problem.

We also extrapolate scattering lengths as shown in \cref{eq:ScatLenExtrap}.
There is no clear convergence pattern for the effective ranges, which are
described in \cref{sec:ScatteringLength}.


\biblio
\end{document}